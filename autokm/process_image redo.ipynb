{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bacb9424",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For refactoring code and making adjustments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f729a6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from pytesseract import pytesseract\n",
    "import pyautogui\n",
    "import os\n",
    "import webbrowser\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pytesseract import Output\n",
    "import imutils\n",
    "import string \n",
    "from thefuzz import fuzz\n",
    "from Levenshtein import distance, ratio\n",
    "from numba import njit\n",
    "\n",
    "\n",
    "def clean_word(word):\n",
    "    for char in word:\n",
    "        if char in string.punctuation:\n",
    "            word = word.replace(char, \"\")\n",
    "            \n",
    "    for char in word:\n",
    "        if not char.isalnum():\n",
    "            word = word.replace(char, \"\")\n",
    "            \n",
    "    return word.strip().lower()\n",
    "\n",
    "\n",
    "def clean_df(df):\n",
    "    df['text'] = df['text'].apply(lambda x: clean_word(x))\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        if row['text'] == \"\":\n",
    "            df.at[i, 'text'] = np.nan\n",
    "            \n",
    "    df.dropna(inplace=True)\n",
    "    df.reset_index(inplace=True)\n",
    "    \n",
    "    #pad dataframe for later use\n",
    "    for _ in range(3):\n",
    "        df = df.append(pd.Series(\"endofdataframe\", index=df.columns), ignore_index=True)\n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "@njit\n",
    "def check_image_background(img):\n",
    "    \"\"\"Checks if a screenshots background is mainly white\n",
    "        Will not invert if it is mainly white, changing a\n",
    "        white photo to black will reduce performance because in\n",
    "        docs it says algo performs best on white backgrounds\"\"\"\n",
    "    score = 0\n",
    "    PIXEL_MIN = 240\n",
    "    SCORE_THRESHOLD = 0.7\n",
    "\n",
    "\n",
    "    height, width, _ = img.shape\n",
    "    \n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            if img[i, j][0] >= PIXEL_MIN and img[i, j][1] >=  PIXEL_MIN and img[i, j][2] >= PIXEL_MIN:\n",
    "                score = score + 1\n",
    "                \n",
    "    if (score / (height*width)) < SCORE_THRESHOLD:\n",
    "        return 1\n",
    "    \n",
    "    return 0\n",
    "\n",
    "\n",
    "\n",
    "### PROCESSING OPTIONS ###\n",
    "## BINARIZATION METHODS ## - Can fine tune each\n",
    "#1 thresh, im_bw = cv2.threshold(gray_image, 210, 230, cv2.THRESH_BINARY)\n",
    "#2 th2 = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY,11,2)\n",
    "#3 th3 = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)\n",
    "\n",
    "#Otsu Binarization\n",
    "\n",
    "# Otsu's thresholding\n",
    "#ret2,th2 = cv2.threshold(img,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "# Otsu's thresholding after Gaussian filtering\n",
    "#blur = cv.GaussianBlur(img,(5,5),0)\n",
    "#ret3,th3 = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "\n",
    "#IDEA FOR BLACK -> OLD METHOD invert then gray (213 items found on spoitfy songs like clair)\n",
    "#1 INVERT\n",
    "#2 GRAYSCALE\n",
    "#3 BINARIZATION -> Gaussian\n",
    "#Lots of noise after this method but 246 items found\n",
    "#After trying noise removal or thick font -> Do not use, bad\n",
    "\n",
    "\n",
    "#IDEA FOR WHITE BACKground\n",
    "#1 convert grayscale\n",
    "#2 some for of binarization\n",
    "#3 remove noise from binarization\n",
    "# Best Process so far -> gray then adaptive thresh mean (gray adaptive mean thick font 474 items found on page)\n",
    "# Runner Up -> gray then adaptive thresh mean then thick font (gray adaptive mean thick font 440 items found on page)\n",
    "#Both are great actually must test more\n",
    "\n",
    "\n",
    "\n",
    "def preprocesser(file_path):\n",
    "    \"\"\"Allows for different preprocessing techniques to be added\n",
    "    onto our input image to improve tesseract\"\"\"\n",
    "    \n",
    "    \n",
    "    base_image = cv2.imread(file_path)\n",
    "    \n",
    "    #Current process inverts mainly black screenshots and coverts to grayscale\n",
    "    #Same process for white but no inverting (try binarization for white)\n",
    "    \n",
    "    #Black backgroun\n",
    "    if check_image_background(base_image):\n",
    "        inverted_image = cv2.bitwise_not(base_image)\n",
    "        gray_image = cv2.cvtColor(inverted_image, cv2.COLOR_BGR2GRAY)\n",
    "        binarized_image = cv2.adaptiveThreshold(gray_image,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)\n",
    "\n",
    "        return gray_image\n",
    "        \n",
    "    #White background\n",
    "    else:\n",
    "        gray_image = cv2.cvtColor(base_image, cv2.COLOR_BGR2GRAY)\n",
    "        binarized_image_mean = cv2.adaptiveThreshold(gray_image,255,cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY,11,2) #Solid but not great\n",
    "        binarized_image_gauss = cv2.adaptiveThreshold(gray_image,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2) #Better\n",
    "        \n",
    "        #Both are actually good must test more and maybe adjust so the colors blue and orange get changed wht & nt blk\n",
    "        \n",
    "        return gray_image\n",
    "\n",
    "\n",
    "def preprocesser2(file_path):\n",
    "    \"\"\"Exact same as preprocessor but if screen is white we do the black operations \"\"\"\n",
    "    \n",
    "    \n",
    "    base_image = cv2.imread(file_path)\n",
    "    \n",
    "    #Current process inverts mainly black screenshots and coverts to grayscale\n",
    "    #Same process for white but no inverting (try binarization for white)\n",
    "    #Black backgroun\n",
    "    if check_image_background(base_image):\n",
    "        gray_image = cv2.cvtColor(base_image, cv2.COLOR_BGR2GRAY)\n",
    "        binarized_image_mean = cv2.adaptiveThreshold(gray_image,255,cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY,11,2) #Solid but not great\n",
    "        binarized_image_gauss = cv2.adaptiveThreshold(gray_image,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2) #Better\n",
    "        \n",
    "        return gray_image\n",
    "        \n",
    "    #White background\n",
    "    else:\n",
    "        inverted_image = cv2.bitwise_not(base_image)\n",
    "        gray_image = cv2.cvtColor(inverted_image, cv2.COLOR_BGR2GRAY)\n",
    "        binarized_image = cv2.adaptiveThreshold(gray_image,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)\n",
    "\n",
    "        return gray_image\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def process_image(file_path):\n",
    "    psm_version = \"--psm 11\"\n",
    "    \n",
    "    preprocessed_image = preprocesser(file_path)\n",
    "    image_df = pd.DataFrame(pytesseract.image_to_data(preprocessed_image, output_type=Output.DICT, config=psm_version))\n",
    "\n",
    "    n_boxes = len(image_df['level'])\n",
    "    for i in range(n_boxes):\n",
    "        (x, y, w, h) = (image_df['left'][i], image_df['top'][i], image_df['width'][i], image_df['height'][i])\n",
    "        cv2.rectangle(preprocessed_image, (x, y), (x + w, y + h), (0,0,0), 2)\n",
    "\n",
    "    cv2.imshow('img', preprocessed_image)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "    \n",
    "    image_df = clean_df(image_df)\n",
    "\n",
    "    return image_df\n",
    "\n",
    "\n",
    "def process_image2(file_path):\n",
    "    psm_version = \"--psm 11\"\n",
    "    \n",
    "    preprocessed_image = preprocesser2(file_path)\n",
    "    image_df = pd.DataFrame(pytesseract.image_to_data(preprocessed_image, output_type=Output.DICT, config=psm_version))\n",
    "\n",
    "    n_boxes = len(image_df['level'])\n",
    "    for i in range(n_boxes):\n",
    "        (x, y, w, h) = (image_df['left'][i], image_df['top'][i], image_df['width'][i], image_df['height'][i])\n",
    "        cv2.rectangle(preprocessed_image, (x, y), (x + w, y + h), (0,0,0), 2)\n",
    "\n",
    "    cv2.imshow('img', preprocessed_image)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "    \n",
    "    image_df = clean_df(image_df)\n",
    "\n",
    "    return image_df\n",
    "\n",
    "\n",
    "\n",
    "def process_coordinates(text_row):\n",
    "    x = text_row['left'] + (text_row['width'] // 1.5)\n",
    "    y = text_row['top'] + (text_row['height'] // 1.5)\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "\n",
    "\n",
    "#Now take image data and find worddef locate_text(df, text):\n",
    "def locate_text(df, text):\n",
    "    results = []\n",
    "\n",
    "    stripped_text = \"\".join(text.lower().split())\n",
    "    split_text = text.split()\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        word = row['text']\n",
    "\n",
    "        second_word = df.iloc[i+1]['text']\n",
    "\n",
    "        initial_fuzz = fuzz.ratio(word, stripped_text)\n",
    "        second_fuzz = fuzz.ratio((word+second_word), stripped_text)\n",
    "        \n",
    "        if word == \"endofdataframe\":\n",
    "            break\n",
    "            \n",
    "        if initial_fuzz >= 80:\n",
    "            if initial_fuzz < second_fuzz:\n",
    "                results.append([(word+second_word), process_coordinates(row), second_fuzz])\n",
    "                \n",
    "            else:\n",
    "                results.append([word, process_coordinates(row), initial_fuzz])\n",
    "\n",
    "\n",
    "        if second_fuzz >= 80 and initial_fuzz < 80:\n",
    "            results.append([(word+second_word), process_coordinates(row), second_fuzz])\n",
    "                \n",
    "                \n",
    "        else:\n",
    "            if word in split_text[0] or split_text[0] in word: #may need to do partial_ratio(split_text[0], word)\n",
    "                word = word\n",
    "                second_word = word + df.iloc[i+1]['text']\n",
    "                \n",
    "                r1 = fuzz.ratio(word, stripped_text)\n",
    "                r2 = fuzz.ratio(second_word, stripped_text)\n",
    "                \n",
    "                j = i + 2 #sets j to current word in df\n",
    "                count = 0\n",
    "                \n",
    "                while r2 >= r1:\n",
    "                    word = second_word\n",
    "                    second_word = word + df.iloc[j]['text']\n",
    "                    \n",
    "                    r1 = fuzz.ratio(word, stripped_text)\n",
    "                    r2 = fuzz.ratio(second_word, stripped_text)\n",
    "                    \n",
    "                    if r2 >= 80:\n",
    "                        results.append([second_word, process_coordinates(row), r2])\n",
    "                    \n",
    "                    word = second_word\n",
    "                    #print(word)\n",
    "                \n",
    "                    count += 1\n",
    "                    j+=1\n",
    "                \n",
    "    return results\n",
    "\n",
    "\n",
    "def find_best_location(r1, r2):\n",
    "    results = []\n",
    "    [results.append(location) for location in r1]\n",
    "    [results.append(location) for location in r2]\n",
    "\n",
    "    highest_fuzz = 0\n",
    "    for location in results:\n",
    "        highest_fuzz = max(highest_fuzz, location[2])\n",
    "\n",
    "\n",
    "\n",
    "    for location in results:\n",
    "        if location[2] == highest_fuzz:\n",
    "            return location\n",
    "            \n",
    "            \n",
    "            \n",
    "def text_coordinates(image_path, text):\n",
    "    \"\"\"Given a list of text coordinates, returns the most accurate texts location\"\"\"\n",
    "    current_dir = os.getcwd()\n",
    "    path_to_tesseract = r\"C:\\Users\\sbuca\\Documents\\pierre\\autokm\\Tesseract-OCR\\tesseract.exe\" #will fail in jupyter folder\n",
    "\n",
    "    pytesseract.tesseract_cmd = path_to_tesseract\n",
    "    \n",
    "    \n",
    "    df = process_image(image_path)\n",
    "    df2 = process_image2(image_path)\n",
    "\n",
    "    results = locate_text(df,text)\n",
    "    results2 = locate_text(df2,text)\n",
    "\n",
    "    if results == [] and results2 == []:\n",
    "        return None\n",
    "    \n",
    "    target = find_best_location(results, results2)\n",
    "\n",
    "    return target[1]\n",
    "    #return (status, coors, df)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    text_coordinates(image_path, text)\n",
    "    process_image(image_path)\n",
    "    process_image2(image_path)\n",
    "    locate_text(df,text)\n",
    "    find_best_location(r1, r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae71394a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from pytesseract import pytesseract\n",
    "import pyautogui\n",
    "import os\n",
    "import webbrowser\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pytesseract import Output\n",
    "import imutils\n",
    "import string \n",
    "from thefuzz import fuzz\n",
    "from Levenshtein import distance, ratio\n",
    "from numba import njit\n",
    "import mss\n",
    "from multiprocessing import Process\n",
    "import threading\n",
    "from datetime import datetime\n",
    "import time\n",
    "from thefuzz import fuzz\n",
    "\n",
    "\n",
    "def clean_word(word):\n",
    "    for char in word:\n",
    "        if char in string.punctuation:\n",
    "            word = word.replace(char, \"\")\n",
    "            \n",
    "    for char in word:\n",
    "        if not char.isalnum():\n",
    "            word = word.replace(char, \"\")\n",
    "            \n",
    "    return word.strip().lower()\n",
    "\n",
    "\n",
    "def clean_df(df):\n",
    "    df['text'] = df['text'].apply(lambda x: clean_word(x))\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        if row['text'] == \"\":\n",
    "            df.at[i, 'text'] = np.nan\n",
    "            \n",
    "    df.dropna(inplace=True)\n",
    "    df.reset_index(inplace=True)\n",
    "    \n",
    "    #pad dataframe for later use\n",
    "    for _ in range(3):\n",
    "        df = df.append(pd.Series(\"endofdataframe\", index=df.columns), ignore_index=True)\n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "@njit\n",
    "def check_image_background(img):\n",
    "    \"\"\"Checks if a screenshots background is mainly white\n",
    "        Will not invert if it is mainly white, changing a\n",
    "        white photo to black will reduce performance because in\n",
    "        docs it says algo performs best on white backgrounds\"\"\"\n",
    "    score = 0\n",
    "    PIXEL_MIN = 240\n",
    "    SCORE_THRESHOLD = 0.7\n",
    "\n",
    "\n",
    "    height, width, _ = img.shape\n",
    "    \n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            if img[i, j][0] >= PIXEL_MIN and img[i, j][1] >=  PIXEL_MIN and img[i, j][2] >= PIXEL_MIN:\n",
    "                score = score + 1\n",
    "                \n",
    "    if (score / (height*width)) < SCORE_THRESHOLD:\n",
    "        return 1\n",
    "    \n",
    "    return 0\n",
    "\n",
    "\n",
    "def preprocesser(file_path, opposite=False):\n",
    "    \"\"\"Allows for different preprocessing techniques to be added\n",
    "    onto our input image to improve tesseract\"\"\"\n",
    "    \n",
    "    \n",
    "    base_image = cv2.imread(file_path)\n",
    "    \n",
    "    #Current process inverts mainly black screenshots and coverts to grayscale\n",
    "    #Same process for white but no inverting (try binarization for white)\n",
    "    \n",
    "    #Cant think of a better solution for the control flow of the opposite -> will think of one late\n",
    "    if opposite is False:\n",
    "        #For photos with mainly Black background\n",
    "        if check_image_background(base_image):\n",
    "            inverted_image = cv2.bitwise_not(base_image)\n",
    "            gray_image = cv2.cvtColor(inverted_image, cv2.COLOR_BGR2GRAY)\n",
    "            binarized_image = cv2.adaptiveThreshold(gray_image,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)\n",
    "\n",
    "            return gray_image\n",
    "\n",
    "\n",
    "        #For photos with mainly White background\n",
    "        else:\n",
    "            gray_image = cv2.cvtColor(base_image, cv2.COLOR_BGR2GRAY)\n",
    "            binarized_image_mean = cv2.adaptiveThreshold(gray_image,255,cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY,11,2) #Solid but not great\n",
    "            binarized_image_gauss = cv2.adaptiveThreshold(gray_image,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2) #Better\n",
    "\n",
    "            #Both are actually good must test more and maybe adjust so the colors blue and orange get changed wht & nt blk\n",
    "\n",
    "            return gray_image\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        if not check_image_background(base_image):\n",
    "            inverted_image = cv2.bitwise_not(base_image)\n",
    "            gray_image = cv2.cvtColor(inverted_image, cv2.COLOR_BGR2GRAY)\n",
    "            binarized_image = cv2.adaptiveThreshold(gray_image,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)\n",
    "\n",
    "            return gray_image\n",
    "\n",
    "        else:\n",
    "            gray_image = cv2.cvtColor(base_image, cv2.COLOR_BGR2GRAY)\n",
    "            binarized_image_mean = cv2.adaptiveThreshold(gray_image,255,cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY,11,2) #Solid but not great\n",
    "            binarized_image_gauss = cv2.adaptiveThreshold(gray_image,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2) #Better\n",
    "            \n",
    "            return gray_image\n",
    "        \n",
    "        \n",
    "#New program works up to this point\n",
    "\n",
    "        \n",
    "#Multithread the process to speed up the image extraction        \n",
    "def process_image(file_path, df_list, alternative=False, show_image=False):\n",
    "    psm_version = \"--psm 11\"\n",
    "    \n",
    "    preprocessed_image = preprocesser(file_path, alternative)\n",
    "    \n",
    "    image_df = pd.DataFrame(pytesseract.image_to_data(preprocessed_image, output_type=Output.DICT, config=psm_version))\n",
    "    \n",
    "    time.sleep(0.1)\n",
    "\n",
    "    image_df = clean_df(image_df)\n",
    "    \n",
    "    df_list.append(image_df) #Add to a list because idk how to return when multithreading\n",
    "    \n",
    "    if show_image is True:\n",
    "        n_boxes = len(image_df['level'])\n",
    "        for i in range(n_boxes):\n",
    "            (x, y, w, h) = (image_df['left'][i], image_df['top'][i], image_df['width'][i], image_df['height'][i])\n",
    "            cv2.rectangle(preprocessed_image, (x, y), (x + w, y + h), (0,0,0), 2)\n",
    "\n",
    "        cv2.imshow('img', preprocessed_image)\n",
    "        cv2.waitKey(0)\n",
    "        \n",
    "    return\n",
    "\n",
    "    \n",
    "#Pretty sure it works up to here\n",
    "\n",
    "\n",
    "def multithread_image_processing(folder_path, dfs):\n",
    "    image_paths = get_images_paths(folder_path)\n",
    "    \n",
    "    for path in image_paths:\n",
    "        monitor_path = folder_path + \"\\\\\" + path \n",
    "        \n",
    "        threading.Thread(target=process_image, args=(monitor_path, dfs, False,)).start()\n",
    "        threading.Thread(target=process_image, args=(monitor_path, dfs, True,)).start()\n",
    "        \n",
    "    return\n",
    "\n",
    "#start refactoring here\n",
    "\n",
    "\n",
    "#Now extract lines or words from the dataframes\n",
    "def extract_text_lines(image_df):\n",
    "    df = image_df.iloc[:-3]\n",
    "    df = df[df.conf != -1]\n",
    "\n",
    "    df[\"conf\"] = pd.to_numeric(df[\"conf\"], downcast=\"float\")\n",
    "\n",
    "    #Apply only works for single columns\n",
    "    for column in [\"left\", \"top\", \"height\", \"width\"]:\n",
    "        df[column] = pd.to_numeric(df[column], downcast=\"float\")\n",
    "    \n",
    "    \n",
    "    lines = df.groupby(['page_num', 'block_num', 'par_num', 'line_num'])['text'].apply(lambda x: ' '.join(list(x))).tolist()\n",
    "    #Ifuckging hate pandas so much its never wants to let you do things easily\n",
    "    \n",
    "    left_coors = df.groupby(['page_num', 'block_num', 'par_num', 'line_num'])['left'].mean().round().tolist()\n",
    "    top_coors = df.groupby(['page_num', 'block_num', 'par_num', 'line_num'])['top'].mean().round().tolist()\n",
    "    height_coors = df.groupby(['page_num', 'block_num', 'par_num', 'line_num'])['height'].mean().round().tolist()\n",
    "    width_coors = df.groupby(['page_num', 'block_num', 'par_num', 'line_num'])['width'].mean().round().tolist()\n",
    "    \n",
    "    confs = df.groupby(['page_num', 'block_num', 'par_num', 'line_num'])['conf'].mean().tolist()\n",
    "\n",
    "    \n",
    "    return list(zip(lines, left_coors, top_coors, height_coors, width_coors))\n",
    "\n",
    "\n",
    "def phrase_matching(list_of_phrases, target_phrase):\n",
    "    most_similar_phrase = \"\"\n",
    "    highest_fuzz = 0\n",
    "    similar_row = ()\n",
    "    \n",
    "    for row in list_of_phrases:\n",
    "        current_ratio = fuzz.ratio(row[0].lower(),target_phrase.lower())\n",
    "        \n",
    "        if current_ratio > highest_fuzz:\n",
    "            most_similar_phrase = row[0]\n",
    "            highest_fuzz = current_ratio\n",
    "            similar_row = row\n",
    "            \n",
    "    print(most_similar_phrase)\n",
    "    return similar_row, highest_fuzz\n",
    "\n",
    "\n",
    "def best_match(phrases):\n",
    "    max_fuzz = 0\n",
    "    coors = 0\n",
    "    \n",
    "    for match in phrases:\n",
    "        if match[-1] > max_fuzz:\n",
    "            max_fuzz = match[-1]\n",
    "            coors = match[0][1:]\n",
    "            \n",
    "    return coors\n",
    "\n",
    "\n",
    "def process_coordinates(coors):\n",
    "    \"\"\"Returns coors into a clickable item for pyautogui\"\"\"\n",
    "    x = coors[0] + (coors[-1] // 1.5)\n",
    "    y = coors[1] + (coors[-2] // 1.5)\n",
    "    \n",
    "    return x,y\n",
    "\n",
    "\n",
    "def get_images_paths(folder_path):\n",
    "    image_paths = []\n",
    "    for file in os.listdir(folder_path):\n",
    "        if \".png\" in file:\n",
    "            image_paths.append(file)\n",
    "        \n",
    "    return image_paths\n",
    "\n",
    "\n",
    "\n",
    "def phrase_coordinates(target, folder_path):\n",
    "    current_dir = os.getcwd()\n",
    "    path_to_tesseract = r\"C:\\Users\\sbuca\\Documents\\pierre\\autokm\\Tesseract-OCR\\tesseract.exe\" #will fail in jupyter folder\n",
    "\n",
    "    pytesseract.tesseract_cmd = path_to_tesseract\n",
    "    \n",
    "    \n",
    "    target = target.lower()\n",
    "    best_phrases = []\n",
    "    dfs = []\n",
    "    \n",
    "    x1 = datetime.now()\n",
    "    multithread_image_processing(folder_path, dfs)\n",
    "    \n",
    "    while len(dfs) < (len(get_images_paths(folder_path))*2):\n",
    "        time.sleep(0.05)\n",
    "    print(datetime.now()-x1)\n",
    "    \n",
    "    for df in dfs:\n",
    "        phrases = extract_text_lines(df)\n",
    "        best_phrase = phrase_matching(phrases, target)\n",
    "        best_phrases.append(best_phrase)\n",
    "           \n",
    "    final_match = best_match(best_phrases)\n",
    "    \n",
    "    return process_coordinates(final_match)\n",
    "        \n",
    "#Will need to refactor quitte abit -> conver the zip list into a dictionary or something "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d493c5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    text_coordinates(image_path, text)\n",
    "    process_image(image_path)\n",
    "    process_image2(image_path)\n",
    "    locate_text(df,text)\n",
    "    find_best_location(r1, r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5378fe90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:01.884931\n",
      "spotifyi\n",
      "spotifyi\n",
      "songs that hit like clarity\n",
      "songs that hit like clarity\n"
     ]
    }
   ],
   "source": [
    "f_path = r\"C:\\Users\\sbuca\\Documents\\pierre\\music_files\\autogui_screenshots\"\n",
    "x = phrase_coordinates(\"songs that hit like\",f_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94504aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spotifyi\n",
      "spotifyi\n",
      "songs that hit like clarity\n",
      "songs that hit like clarity\n",
      "0:00:02.591290\n"
     ]
    }
   ],
   "source": [
    "x1 = datetime.now()\n",
    "x = phrase_coordinates(\"songs that hit like\",f_path)\n",
    "print(datetime.now()-x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1966fa6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['monitor1.png']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_images_paths(f_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a11e22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_path = r\"C:\\Users\\sbuca\\Documents\\pierre\\music_files\\autogui_screenshots\"\n",
    "# pdgkp = []\n",
    "# multithread_image_processing2(f_path, pdgkp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3264bdfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[              index           level        page_num       block_num  \\\n",
       " 0                 8               5               1               2   \n",
       " 1                13               5               1               3   \n",
       " 2                18               5               1               4   \n",
       " 3                22               5               1               5   \n",
       " 4                26               5               1               6   \n",
       " ..              ...             ...             ...             ...   \n",
       " 216             725               5               1             156   \n",
       " 217             729               5               1             157   \n",
       " 218  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 219  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 220  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " \n",
       "             par_num        line_num        word_num            left  \\\n",
       " 0                 1               1               1            1893   \n",
       " 1                 1               1               2            1656   \n",
       " 2                 1               1               2             511   \n",
       " 3                 1               1               1              64   \n",
       " 4                 1               1               1             641   \n",
       " ..              ...             ...             ...             ...   \n",
       " 216               1               1               1            1378   \n",
       " 217               1               1               1            1829   \n",
       " 218  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 219  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 220  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " \n",
       "                 top           width          height            conf  \\\n",
       " 0                 9              10              10              96   \n",
       " 1                26              66              10              81   \n",
       " 2                11             364              40              55   \n",
       " 3                62              37              10              97   \n",
       " 4                83              40              10              95   \n",
       " ..              ...             ...             ...             ...   \n",
       " 216            1057              18              18              35   \n",
       " 217            1060              48              10              20   \n",
       " 218  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 219  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 220  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " \n",
       "                text  \n",
       " 0                 x  \n",
       " 1         sbucarion  \n",
       " 2                ed  \n",
       " 3              home  \n",
       " 4           artists  \n",
       " ..              ...  \n",
       " 216             cad  \n",
       " 217         arpe023  \n",
       " 218  endofdataframe  \n",
       " 219  endofdataframe  \n",
       " 220  endofdataframe  \n",
       " \n",
       " [221 rows x 13 columns],\n",
       "               index           level        page_num       block_num  \\\n",
       " 0                 9               5               1               2   \n",
       " 1                14               5               1               3   \n",
       " 2                18               5               1               4   \n",
       " 3                22               5               1               5   \n",
       " 4                26               5               1               6   \n",
       " ..              ...             ...             ...             ...   \n",
       " 223             737               5               1             159   \n",
       " 224             741               5               1             160   \n",
       " 225  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 226  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 227  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " \n",
       "             par_num        line_num        word_num            left  \\\n",
       " 0                 1               1               2            1656   \n",
       " 1                 1               1               2             511   \n",
       " 2                 1               1               1              64   \n",
       " 3                 1               1               1             641   \n",
       " 4                 1               1               1             718   \n",
       " ..              ...             ...             ...             ...   \n",
       " 223               1               1               1            1378   \n",
       " 224               1               1               1            1829   \n",
       " 225  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 226  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 227  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " \n",
       "                 top           width          height            conf  \\\n",
       " 0                26              66              10              81   \n",
       " 1                11             364              40              52   \n",
       " 2                62              37              10              96   \n",
       " 3                83              40              10              94   \n",
       " 4                83              50              13              73   \n",
       " ..              ...             ...             ...             ...   \n",
       " 223            1055              18              20              35   \n",
       " 224            1060              48              10              71   \n",
       " 225  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 226  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 227  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " \n",
       "                text  \n",
       " 0         sbucarion  \n",
       " 1                ed  \n",
       " 2              home  \n",
       " 3           artists  \n",
       " 4         playlists  \n",
       " ..              ...  \n",
       " 223             cad  \n",
       " 224          162023  \n",
       " 225  endofdataframe  \n",
       " 226  endofdataframe  \n",
       " 227  endofdataframe  \n",
       " \n",
       " [228 rows x 13 columns],\n",
       "               index           level        page_num       block_num  \\\n",
       " 0                 9               5               1               2   \n",
       " 1                14               5               1               3   \n",
       " 2                18               5               1               4   \n",
       " 3                22               5               1               5   \n",
       " 4                26               5               1               6   \n",
       " ..              ...             ...             ...             ...   \n",
       " 222             735               5               1             159   \n",
       " 223             739               5               1             160   \n",
       " 224  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 225  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 226  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " \n",
       "             par_num        line_num        word_num            left  \\\n",
       " 0                 1               1               2            1656   \n",
       " 1                 1               1               2             511   \n",
       " 2                 1               1               1              64   \n",
       " 3                 1               1               1             641   \n",
       " 4                 1               1               1             718   \n",
       " ..              ...             ...             ...             ...   \n",
       " 222               1               1               1            1378   \n",
       " 223               1               1               1            1829   \n",
       " 224  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 225  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 226  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " \n",
       "                 top           width          height            conf  \\\n",
       " 0                26              66              10              36   \n",
       " 1                11             364              40              57   \n",
       " 2                62              37              10              97   \n",
       " 3                83              40              10              95   \n",
       " 4                83              50              13              76   \n",
       " ..              ...             ...             ...             ...   \n",
       " 222            1055              18              20              42   \n",
       " 223            1060              48              10              69   \n",
       " 224  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 225  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 226  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " \n",
       "                text  \n",
       " 0         sbucarion  \n",
       " 1                ed  \n",
       " 2              home  \n",
       " 3           artists  \n",
       " 4         playlists  \n",
       " ..              ...  \n",
       " 222              ss  \n",
       " 223          162023  \n",
       " 224  endofdataframe  \n",
       " 225  endofdataframe  \n",
       " 226  endofdataframe  \n",
       " \n",
       " [227 rows x 13 columns],\n",
       "               index           level        page_num       block_num  \\\n",
       " 0                 8               5               1               2   \n",
       " 1                13               5               1               3   \n",
       " 2                18               5               1               4   \n",
       " 3                22               5               1               5   \n",
       " 4                26               5               1               6   \n",
       " ..              ...             ...             ...             ...   \n",
       " 216             722               5               1             155   \n",
       " 217             726               5               1             156   \n",
       " 218  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 219  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 220  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " \n",
       "             par_num        line_num        word_num            left  \\\n",
       " 0                 1               1               1            1893   \n",
       " 1                 1               1               2            1656   \n",
       " 2                 1               1               2             511   \n",
       " 3                 1               1               1              64   \n",
       " 4                 1               1               1             641   \n",
       " ..              ...             ...             ...             ...   \n",
       " 216               1               1               1            1378   \n",
       " 217               1               1               1            1829   \n",
       " 218  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 219  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 220  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " \n",
       "                 top           width          height            conf  \\\n",
       " 0                 9              10              10              96   \n",
       " 1                26              66              10              36   \n",
       " 2                11             364              40              58   \n",
       " 3                62              37              10              96   \n",
       " 4                83              40              10              94   \n",
       " ..              ...             ...             ...             ...   \n",
       " 216            1057              18              18              42   \n",
       " 217            1060              48              10               5   \n",
       " 218  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 219  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 220  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " \n",
       "                text  \n",
       " 0                 x  \n",
       " 1         sbucarion  \n",
       " 2                ed  \n",
       " 3              home  \n",
       " 4           artists  \n",
       " ..              ...  \n",
       " 216              ss  \n",
       " 217         arpe023  \n",
       " 218  endofdataframe  \n",
       " 219  endofdataframe  \n",
       " 220  endofdataframe  \n",
       " \n",
       " [221 rows x 13 columns]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdgkp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b2c0daa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sbuca\\Documents\\pierre\\music_files\\autogui_screenshots\\\\monitor1.png\n",
      "C:\\Users\\sbuca\\Documents\\pierre\\music_files\\autogui_screenshots\\\\monitor2.png\n"
     ]
    }
   ],
   "source": [
    "image_paths = get_images_paths(r\"C:\\Users\\sbuca\\Documents\\pierre\\music_files\\autogui_screenshots\")\n",
    "\n",
    "i=0\n",
    "for path in image_paths:\n",
    "    monitor_path = r\"C:\\Users\\sbuca\\Documents\\pierre\\music_files\\autogui_screenshots\\\\\" + path\n",
    "    print(monitor_path)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed44968",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = r\"C:\\Users\\sbuca\\Documents\\pierre\\music_files\\autogui_screenshots\"\n",
    "phrase_coordinates(\"songs that hit like\", folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0fcf2be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".ipynb_checkpoints\n",
      "monitor1.png\n",
      "monitor2.png\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir(r\"C:\\Users\\sbuca\\Documents\\pierre\\music_files\\autogui_screenshots\"):\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "19fe1dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pppp = []\n",
    "xsslolo=[]\n",
    "xsslolo =  multithread_image_processing(\"\", pppp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0756699c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "songs that hit like clarity\n",
      "songs that hit like clarity\n",
      "songs that hit like clarity\n",
      "songs that hit like clarity\n",
      "0:00:02.676638\n"
     ]
    }
   ],
   "source": [
    "x1 = datetime.now() \n",
    "phrase_coordinates(\"songs that hit like\",0, 0)\n",
    "print(datetime.now() - x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "c9fdd8c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103.0, 627.0)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qqq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "c56e2acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = qq[0].groupby(['page_num', 'block_num', 'par_num', 'line_num'])['text'].apply(lambda x: ' '.join(list(x))).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "3969db70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[              index           level        page_num       block_num  \\\n",
       " 0                 8               5               1               2   \n",
       " 1                13               5               1               3   \n",
       " 2                18               5               1               4   \n",
       " 3                22               5               1               5   \n",
       " 4                26               5               1               6   \n",
       " ..              ...             ...             ...             ...   \n",
       " 216             725               5               1             156   \n",
       " 217             729               5               1             157   \n",
       " 218  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 219  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 220  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " \n",
       "             par_num        line_num        word_num            left  \\\n",
       " 0                 1               1               1            1893   \n",
       " 1                 1               1               2            1656   \n",
       " 2                 1               1               2             511   \n",
       " 3                 1               1               1              64   \n",
       " 4                 1               1               1             641   \n",
       " ..              ...             ...             ...             ...   \n",
       " 216               1               1               1            1378   \n",
       " 217               1               1               1            1829   \n",
       " 218  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 219  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 220  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " \n",
       "                 top           width          height            conf  \\\n",
       " 0                 9              10              10              96   \n",
       " 1                26              66              10              81   \n",
       " 2                11             364              40              55   \n",
       " 3                62              37              10              97   \n",
       " 4                83              40              10              95   \n",
       " ..              ...             ...             ...             ...   \n",
       " 216            1057              18              18              35   \n",
       " 217            1060              48              10              20   \n",
       " 218  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 219  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 220  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " \n",
       "                text  \n",
       " 0                 x  \n",
       " 1         sbucarion  \n",
       " 2                ed  \n",
       " 3              home  \n",
       " 4           artists  \n",
       " ..              ...  \n",
       " 216             cad  \n",
       " 217         arpe023  \n",
       " 218  endofdataframe  \n",
       " 219  endofdataframe  \n",
       " 220  endofdataframe  \n",
       " \n",
       " [221 rows x 13 columns],\n",
       "               index           level        page_num       block_num  \\\n",
       " 0                 8               5               1               2   \n",
       " 1                13               5               1               3   \n",
       " 2                18               5               1               4   \n",
       " 3                22               5               1               5   \n",
       " 4                26               5               1               6   \n",
       " ..              ...             ...             ...             ...   \n",
       " 216             722               5               1             155   \n",
       " 217             726               5               1             156   \n",
       " 218  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 219  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 220  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " \n",
       "             par_num        line_num        word_num            left  \\\n",
       " 0                 1               1               1            1893   \n",
       " 1                 1               1               2            1656   \n",
       " 2                 1               1               2             511   \n",
       " 3                 1               1               1              64   \n",
       " 4                 1               1               1             641   \n",
       " ..              ...             ...             ...             ...   \n",
       " 216               1               1               1            1378   \n",
       " 217               1               1               1            1829   \n",
       " 218  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 219  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 220  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " \n",
       "                 top           width          height            conf  \\\n",
       " 0                 9              10              10              96   \n",
       " 1                26              66              10              36   \n",
       " 2                11             364              40              58   \n",
       " 3                62              37              10              96   \n",
       " 4                83              40              10              94   \n",
       " ..              ...             ...             ...             ...   \n",
       " 216            1057              18              18              42   \n",
       " 217            1060              48              10               5   \n",
       " 218  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 219  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 220  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " \n",
       "                text  \n",
       " 0                 x  \n",
       " 1         sbucarion  \n",
       " 2                ed  \n",
       " 3              home  \n",
       " 4           artists  \n",
       " ..              ...  \n",
       " 216              ss  \n",
       " 217         arpe023  \n",
       " 218  endofdataframe  \n",
       " 219  endofdataframe  \n",
       " 220  endofdataframe  \n",
       " \n",
       " [221 rows x 13 columns],\n",
       "               index           level        page_num       block_num  \\\n",
       " 0                 9               5               1               2   \n",
       " 1                14               5               1               3   \n",
       " 2                18               5               1               4   \n",
       " 3                22               5               1               5   \n",
       " 4                26               5               1               6   \n",
       " ..              ...             ...             ...             ...   \n",
       " 223             737               5               1             159   \n",
       " 224             741               5               1             160   \n",
       " 225  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 226  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 227  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " \n",
       "             par_num        line_num        word_num            left  \\\n",
       " 0                 1               1               2            1656   \n",
       " 1                 1               1               2             511   \n",
       " 2                 1               1               1              64   \n",
       " 3                 1               1               1             641   \n",
       " 4                 1               1               1             718   \n",
       " ..              ...             ...             ...             ...   \n",
       " 223               1               1               1            1378   \n",
       " 224               1               1               1            1829   \n",
       " 225  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 226  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 227  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " \n",
       "                 top           width          height            conf  \\\n",
       " 0                26              66              10              81   \n",
       " 1                11             364              40              52   \n",
       " 2                62              37              10              96   \n",
       " 3                83              40              10              94   \n",
       " 4                83              50              13              73   \n",
       " ..              ...             ...             ...             ...   \n",
       " 223            1055              18              20              35   \n",
       " 224            1060              48              10              71   \n",
       " 225  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 226  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 227  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " \n",
       "                text  \n",
       " 0         sbucarion  \n",
       " 1                ed  \n",
       " 2              home  \n",
       " 3           artists  \n",
       " 4         playlists  \n",
       " ..              ...  \n",
       " 223             cad  \n",
       " 224          162023  \n",
       " 225  endofdataframe  \n",
       " 226  endofdataframe  \n",
       " 227  endofdataframe  \n",
       " \n",
       " [228 rows x 13 columns],\n",
       "               index           level        page_num       block_num  \\\n",
       " 0                 9               5               1               2   \n",
       " 1                14               5               1               3   \n",
       " 2                18               5               1               4   \n",
       " 3                22               5               1               5   \n",
       " 4                26               5               1               6   \n",
       " ..              ...             ...             ...             ...   \n",
       " 222             735               5               1             159   \n",
       " 223             739               5               1             160   \n",
       " 224  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 225  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 226  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " \n",
       "             par_num        line_num        word_num            left  \\\n",
       " 0                 1               1               2            1656   \n",
       " 1                 1               1               2             511   \n",
       " 2                 1               1               1              64   \n",
       " 3                 1               1               1             641   \n",
       " 4                 1               1               1             718   \n",
       " ..              ...             ...             ...             ...   \n",
       " 222               1               1               1            1378   \n",
       " 223               1               1               1            1829   \n",
       " 224  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 225  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 226  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " \n",
       "                 top           width          height            conf  \\\n",
       " 0                26              66              10              36   \n",
       " 1                11             364              40              57   \n",
       " 2                62              37              10              97   \n",
       " 3                83              40              10              95   \n",
       " 4                83              50              13              76   \n",
       " ..              ...             ...             ...             ...   \n",
       " 222            1055              18              20              42   \n",
       " 223            1060              48              10              69   \n",
       " 224  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 225  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 226  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " \n",
       "                text  \n",
       " 0         sbucarion  \n",
       " 1                ed  \n",
       " 2              home  \n",
       " 3           artists  \n",
       " 4         playlists  \n",
       " ..              ...  \n",
       " 222              ss  \n",
       " 223          162023  \n",
       " 224  endofdataframe  \n",
       " 225  endofdataframe  \n",
       " 226  endofdataframe  \n",
       " \n",
       " [227 rows x 13 columns]]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "b1b651a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-07 12:46:46.509957\n",
      "0:00:02.291216\n"
     ]
    }
   ],
   "source": [
    "monitor1_path = r\"C:\\Users\\sbuca\\Documents\\pierre\\music_files\\autogui_screenshots\\monitor1.png\"\n",
    "monitor2_path = r\"C:\\Users\\sbuca\\Documents\\pierre\\music_files\\autogui_screenshots\\monitor2.png\"\n",
    "\n",
    "x1 = (datetime.now())\n",
    "print(x1)\n",
    "xxvb = multithread_image_processing2(monitor1_path,monitor2_path)\n",
    "print(datetime.now()-x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "6c13517d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[              index           level        page_num       block_num  \\\n",
       " 0                 8               5               1               2   \n",
       " 1                13               5               1               3   \n",
       " 2                18               5               1               4   \n",
       " 3                22               5               1               5   \n",
       " 4                26               5               1               6   \n",
       " ..              ...             ...             ...             ...   \n",
       " 216             725               5               1             156   \n",
       " 217             729               5               1             157   \n",
       " 218  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 219  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 220  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " \n",
       "             par_num        line_num        word_num            left  \\\n",
       " 0                 1               1               1            1893   \n",
       " 1                 1               1               2            1656   \n",
       " 2                 1               1               2             511   \n",
       " 3                 1               1               1              64   \n",
       " 4                 1               1               1             641   \n",
       " ..              ...             ...             ...             ...   \n",
       " 216               1               1               1            1378   \n",
       " 217               1               1               1            1829   \n",
       " 218  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 219  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 220  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " \n",
       "                 top           width          height            conf  \\\n",
       " 0                 9              10              10              96   \n",
       " 1                26              66              10              81   \n",
       " 2                11             364              40              55   \n",
       " 3                62              37              10              97   \n",
       " 4                83              40              10              95   \n",
       " ..              ...             ...             ...             ...   \n",
       " 216            1057              18              18              35   \n",
       " 217            1060              48              10              20   \n",
       " 218  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 219  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 220  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " \n",
       "                text  \n",
       " 0                 x  \n",
       " 1         sbucarion  \n",
       " 2                ed  \n",
       " 3              home  \n",
       " 4           artists  \n",
       " ..              ...  \n",
       " 216             cad  \n",
       " 217         arpe023  \n",
       " 218  endofdataframe  \n",
       " 219  endofdataframe  \n",
       " 220  endofdataframe  \n",
       " \n",
       " [221 rows x 13 columns],\n",
       "               index           level        page_num       block_num  \\\n",
       " 0                 8               5               1               2   \n",
       " 1                13               5               1               3   \n",
       " 2                18               5               1               4   \n",
       " 3                22               5               1               5   \n",
       " 4                26               5               1               6   \n",
       " ..              ...             ...             ...             ...   \n",
       " 216             722               5               1             155   \n",
       " 217             726               5               1             156   \n",
       " 218  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 219  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 220  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " \n",
       "             par_num        line_num        word_num            left  \\\n",
       " 0                 1               1               1            1893   \n",
       " 1                 1               1               2            1656   \n",
       " 2                 1               1               2             511   \n",
       " 3                 1               1               1              64   \n",
       " 4                 1               1               1             641   \n",
       " ..              ...             ...             ...             ...   \n",
       " 216               1               1               1            1378   \n",
       " 217               1               1               1            1829   \n",
       " 218  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 219  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 220  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " \n",
       "                 top           width          height            conf  \\\n",
       " 0                 9              10              10              96   \n",
       " 1                26              66              10              36   \n",
       " 2                11             364              40              58   \n",
       " 3                62              37              10              96   \n",
       " 4                83              40              10              94   \n",
       " ..              ...             ...             ...             ...   \n",
       " 216            1057              18              18              42   \n",
       " 217            1060              48              10               5   \n",
       " 218  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 219  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 220  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " \n",
       "                text  \n",
       " 0                 x  \n",
       " 1         sbucarion  \n",
       " 2                ed  \n",
       " 3              home  \n",
       " 4           artists  \n",
       " ..              ...  \n",
       " 216              ss  \n",
       " 217         arpe023  \n",
       " 218  endofdataframe  \n",
       " 219  endofdataframe  \n",
       " 220  endofdataframe  \n",
       " \n",
       " [221 rows x 13 columns],\n",
       "               index           level        page_num       block_num  \\\n",
       " 0                 9               5               1               2   \n",
       " 1                14               5               1               3   \n",
       " 2                18               5               1               4   \n",
       " 3                22               5               1               5   \n",
       " 4                26               5               1               6   \n",
       " ..              ...             ...             ...             ...   \n",
       " 223             737               5               1             159   \n",
       " 224             741               5               1             160   \n",
       " 225  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 226  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 227  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " \n",
       "             par_num        line_num        word_num            left  \\\n",
       " 0                 1               1               2            1656   \n",
       " 1                 1               1               2             511   \n",
       " 2                 1               1               1              64   \n",
       " 3                 1               1               1             641   \n",
       " 4                 1               1               1             718   \n",
       " ..              ...             ...             ...             ...   \n",
       " 223               1               1               1            1378   \n",
       " 224               1               1               1            1829   \n",
       " 225  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 226  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 227  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " \n",
       "                 top           width          height            conf  \\\n",
       " 0                26              66              10              81   \n",
       " 1                11             364              40              52   \n",
       " 2                62              37              10              96   \n",
       " 3                83              40              10              94   \n",
       " 4                83              50              13              73   \n",
       " ..              ...             ...             ...             ...   \n",
       " 223            1055              18              20              35   \n",
       " 224            1060              48              10              71   \n",
       " 225  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 226  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 227  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " \n",
       "                text  \n",
       " 0         sbucarion  \n",
       " 1                ed  \n",
       " 2              home  \n",
       " 3           artists  \n",
       " 4         playlists  \n",
       " ..              ...  \n",
       " 223             cad  \n",
       " 224          162023  \n",
       " 225  endofdataframe  \n",
       " 226  endofdataframe  \n",
       " 227  endofdataframe  \n",
       " \n",
       " [228 rows x 13 columns],\n",
       "               index           level        page_num       block_num  \\\n",
       " 0                 9               5               1               2   \n",
       " 1                14               5               1               3   \n",
       " 2                18               5               1               4   \n",
       " 3                22               5               1               5   \n",
       " 4                26               5               1               6   \n",
       " ..              ...             ...             ...             ...   \n",
       " 222             735               5               1             159   \n",
       " 223             739               5               1             160   \n",
       " 224  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 225  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 226  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " \n",
       "             par_num        line_num        word_num            left  \\\n",
       " 0                 1               1               2            1656   \n",
       " 1                 1               1               2             511   \n",
       " 2                 1               1               1              64   \n",
       " 3                 1               1               1             641   \n",
       " 4                 1               1               1             718   \n",
       " ..              ...             ...             ...             ...   \n",
       " 222               1               1               1            1378   \n",
       " 223               1               1               1            1829   \n",
       " 224  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 225  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 226  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " \n",
       "                 top           width          height            conf  \\\n",
       " 0                26              66              10              36   \n",
       " 1                11             364              40              57   \n",
       " 2                62              37              10              97   \n",
       " 3                83              40              10              95   \n",
       " 4                83              50              13              76   \n",
       " ..              ...             ...             ...             ...   \n",
       " 222            1055              18              20              42   \n",
       " 223            1060              48              10              69   \n",
       " 224  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 225  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " 226  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       " \n",
       "                text  \n",
       " 0         sbucarion  \n",
       " 1                ed  \n",
       " 2              home  \n",
       " 3           artists  \n",
       " 4         playlists  \n",
       " ..              ...  \n",
       " 222              ss  \n",
       " 223          162023  \n",
       " 224  endofdataframe  \n",
       " 225  endofdataframe  \n",
       " 226  endofdataframe  \n",
       " \n",
       " [227 rows x 13 columns]]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xxvb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "78381d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-06 23:08:55.823972\n",
      "0:00:02.028067\n"
     ]
    }
   ],
   "source": [
    "x1 = (datetime.now())\n",
    "print(x1)\n",
    "xxvb = multithread_image_processing(\"\")\n",
    "print(datetime.now()-x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "1582c9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pe to\n",
      "pe to\n",
      "we up 3\n",
      "we up 3\n",
      "(47.0, 587.0, 11.0, 14.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(56.0, 594.0)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase_coordinates(xxvb, \"We Up 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "d9563864",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyautogui.moveTo(103.0, 627.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "08e039fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(590.0, 1044.0, 31.0, 364.0, 0.0)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(('bcvrmaaort', 590.0, 1044.0, 31.0, 364.0, 0.0), 39)[0][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17ee4926",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mss\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "with mss.mss() as sct:\n",
    "    \n",
    "    # Get information of monitor 2\n",
    "    monitor_number = 2\n",
    "    mon = sct.monitors[monitor_number]\n",
    "\n",
    "    # The screen part to capture\n",
    "    monitor = {\n",
    "        \"top\": mon[\"top\"],\n",
    "        \"left\": mon[\"left\"],\n",
    "        \"width\": mon[\"width\"],\n",
    "        \"height\": mon[\"height\"],\n",
    "        \"mon\": monitor_number,\n",
    "    }\n",
    "    output = \"sct-mon{mon}_{top}x{left}_{width}x{height}.png\".format(**monitor)\n",
    "\n",
    "    # Grab the data\n",
    "    sct_img = sct.grab(monitor)\n",
    "    \n",
    "    \n",
    "#     mss.tools.to_png(sct_img.rgb, sct_img.size, ou\n",
    "#                      tput=r\"C:\\Users\\sbuca\\Documents\\pierre\\music_files\\autogui_screenshots\\monitor2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8883888a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, len(sct.monitors)):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9db580a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor1_path = r\"C:\\Users\\sbuca\\Documents\\pierre\\music_files\\autogui_screenshots\\monitor1.png\"\n",
    "monitor2_path = r\"C:\\Users\\sbuca\\Documents\\pierre\\music_files\\autogui_screenshots\\monitor2.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "75957c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.186502\n",
      "0:00:01.461094\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>level</th>\n",
       "      <th>page_num</th>\n",
       "      <th>block_num</th>\n",
       "      <th>par_num</th>\n",
       "      <th>line_num</th>\n",
       "      <th>word_num</th>\n",
       "      <th>left</th>\n",
       "      <th>top</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>conf</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1728</td>\n",
       "      <td>17</td>\n",
       "      <td>41</td>\n",
       "      <td>8</td>\n",
       "      <td>73</td>\n",
       "      <td>seabass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1873</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>70</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1892</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>70</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1605</td>\n",
       "      <td>9</td>\n",
       "      <td>70</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>el</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "      <td>46</td>\n",
       "      <td>70</td>\n",
       "      <td>15</td>\n",
       "      <td>96</td>\n",
       "      <td>store</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>926</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>182</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1356</td>\n",
       "      <td>1057</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>41</td>\n",
       "      <td>ss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>930</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>183</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1829</td>\n",
       "      <td>1060</td>\n",
       "      <td>48</td>\n",
       "      <td>10</td>\n",
       "      <td>76</td>\n",
       "      <td>162023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>endofdataframe</td>\n",
       "      <td>endofdataframe</td>\n",
       "      <td>endofdataframe</td>\n",
       "      <td>endofdataframe</td>\n",
       "      <td>endofdataframe</td>\n",
       "      <td>endofdataframe</td>\n",
       "      <td>endofdataframe</td>\n",
       "      <td>endofdataframe</td>\n",
       "      <td>endofdataframe</td>\n",
       "      <td>endofdataframe</td>\n",
       "      <td>endofdataframe</td>\n",
       "      <td>endofdataframe</td>\n",
       "      <td>endofdataframe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>endofdataframe</td>\n",
       "      <td>endofdataframe</td>\n",
       "      <td>endofdataframe</td>\n",
       "      <td>endofdataframe</td>\n",
       "      <td>endofdataframe</td>\n",
       "      <td>endofdataframe</td>\n",
       "      <td>endofdataframe</td>\n",
       "      <td>endofdataframe</td>\n",
       "      <td>endofdataframe</td>\n",
       "      <td>endofdataframe</td>\n",
       "      <td>endofdataframe</td>\n",
       "      <td>endofdataframe</td>\n",
       "      <td>endofdataframe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>endofdataframe</td>\n",
       "      <td>endofdataframe</td>\n",
       "      <td>endofdataframe</td>\n",
       "      <td>endofdataframe</td>\n",
       "      <td>endofdataframe</td>\n",
       "      <td>endofdataframe</td>\n",
       "      <td>endofdataframe</td>\n",
       "      <td>endofdataframe</td>\n",
       "      <td>endofdataframe</td>\n",
       "      <td>endofdataframe</td>\n",
       "      <td>endofdataframe</td>\n",
       "      <td>endofdataframe</td>\n",
       "      <td>endofdataframe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>339 rows  13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              index           level        page_num       block_num  \\\n",
       "0                 4               5               1               1   \n",
       "1                 9               5               1               2   \n",
       "2                10               5               1               2   \n",
       "3                15               5               1               3   \n",
       "4                19               5               1               4   \n",
       "..              ...             ...             ...             ...   \n",
       "334             926               5               1             182   \n",
       "335             930               5               1             183   \n",
       "336  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       "337  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       "338  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       "\n",
       "            par_num        line_num        word_num            left  \\\n",
       "0                 1               1               1            1728   \n",
       "1                 1               1               1            1873   \n",
       "2                 1               1               2            1892   \n",
       "3                 1               1               2            1605   \n",
       "4                 1               1               1              81   \n",
       "..              ...             ...             ...             ...   \n",
       "334               1               1               1            1356   \n",
       "335               1               1               1            1829   \n",
       "336  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       "337  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       "338  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       "\n",
       "                top           width          height            conf  \\\n",
       "0                17              41               8              73   \n",
       "1                17               6               5              70   \n",
       "2                16              10               9              70   \n",
       "3                 9              70              24               2   \n",
       "4                46              70              15              96   \n",
       "..              ...             ...             ...             ...   \n",
       "334            1057              18              18              41   \n",
       "335            1060              48              10              76   \n",
       "336  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       "337  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       "338  endofdataframe  endofdataframe  endofdataframe  endofdataframe   \n",
       "\n",
       "               text  \n",
       "0           seabass  \n",
       "1                 a  \n",
       "2                 x  \n",
       "3                el  \n",
       "4             store  \n",
       "..              ...  \n",
       "334              ss  \n",
       "335          162023  \n",
       "336  endofdataframe  \n",
       "337  endofdataframe  \n",
       "338  endofdataframe  \n",
       "\n",
       "[339 rows x 13 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "path_to_tesseract = r\"C:\\Users\\sbuca\\Documents\\pierre\\autokm\\Tesseract-OCR\\tesseract.exe\" #will fail in jupyter folder\n",
    "\n",
    "pytesseract.tesseract_cmd = path_to_tesseract\n",
    "\n",
    "process_image(file_path, alternative=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23c4f2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"C:\\Users\\sbuca\\Documents\\pierre\\music_files\\autogui_screenshots\\spotify_screenshot.png\"\n",
    "preprocessed_image = preprocesser(file_path, opposite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb8c4e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow('img', preprocessed_image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00b3baa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[209, 210, 210, ..., 230, 230, 230],\n",
       "       [209, 223, 222, ..., 226, 226, 230],\n",
       "       [209, 223, 223, ..., 226, 226, 230],\n",
       "       ...,\n",
       "       [222, 223, 223, ..., 223, 223, 221],\n",
       "       [222, 223, 223, ..., 224, 223, 224],\n",
       "       [222, 221, 222, ..., 222, 222, 223]], dtype=uint8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfa23c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c805883",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdc3fde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c2f56b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481e69b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab3d683",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d0f6bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c00def7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba54cd8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb679f80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8d4e7659",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from pytesseract import pytesseract\n",
    "import pyautogui\n",
    "import os\n",
    "import webbrowser\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pytesseract import Output\n",
    "import imutils\n",
    "import string \n",
    "from thefuzz import fuzz\n",
    "from Levenshtein import distance, ratio\n",
    "from numba import njit\n",
    "import mss\n",
    "from multiprocessing import Process\n",
    "import threading\n",
    "from datetime import datetime\n",
    "import time\n",
    "from thefuzz import fuzz\n",
    "\n",
    "\n",
    "def clean_word(word):\n",
    "    for char in word:\n",
    "        if char in string.punctuation:\n",
    "            word = word.replace(char, \"\")\n",
    "            \n",
    "    for char in word:\n",
    "        if not char.isalnum():\n",
    "            word = word.replace(char, \"\")\n",
    "            \n",
    "    return word.strip().lower()\n",
    "\n",
    "\n",
    "def clean_df(df):\n",
    "    df['text'] = df['text'].apply(lambda x: clean_word(x))\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        if row['text'] == \"\":\n",
    "            df.at[i, 'text'] = np.nan\n",
    "            \n",
    "    df.dropna(inplace=True)\n",
    "    df.reset_index(inplace=True)\n",
    "    \n",
    "    #pad dataframe for later use\n",
    "    for _ in range(3):\n",
    "        df = df.append(pd.Series(\"endofdataframe\", index=df.columns), ignore_index=True)\n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "@njit\n",
    "def check_image_background(img):\n",
    "    \"\"\"Checks if a screenshots background is mainly white\n",
    "        Will not invert if it is mainly white, changing a\n",
    "        white photo to black will reduce performance because in\n",
    "        docs it says algo performs best on white backgrounds\"\"\"\n",
    "    score = 0\n",
    "    PIXEL_MIN = 240\n",
    "    SCORE_THRESHOLD = 0.7\n",
    "\n",
    "\n",
    "    height, width, _ = img.shape\n",
    "    \n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            if img[i, j][0] >= PIXEL_MIN and img[i, j][1] >=  PIXEL_MIN and img[i, j][2] >= PIXEL_MIN:\n",
    "                score = score + 1\n",
    "                \n",
    "    if (score / (height*width)) < SCORE_THRESHOLD:\n",
    "        return 1\n",
    "    \n",
    "    return 0\n",
    "\n",
    "\n",
    "def preprocesser(file_path, opposite=False):\n",
    "    \"\"\"Allows for different preprocessing techniques to be added\n",
    "    onto our input image to improve tesseract\"\"\"\n",
    "    \n",
    "    \n",
    "    base_image = cv2.imread(file_path)\n",
    "    \n",
    "    #Current process inverts mainly black screenshots and coverts to grayscale\n",
    "    #Same process for white but no inverting (try binarization for white)\n",
    "    \n",
    "    #Cant think of a better solution for the control flow of the opposite -> will think of one late\n",
    "    if opposite is False:\n",
    "        #For photos with mainly Black background\n",
    "        if check_image_background(base_image):\n",
    "            inverted_image = cv2.bitwise_not(base_image)\n",
    "            gray_image = cv2.cvtColor(inverted_image, cv2.COLOR_BGR2GRAY)\n",
    "            binarized_image = cv2.adaptiveThreshold(gray_image,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)\n",
    "\n",
    "            return gray_image\n",
    "\n",
    "\n",
    "        #For photos with mainly White background\n",
    "        else:\n",
    "            gray_image = cv2.cvtColor(base_image, cv2.COLOR_BGR2GRAY)\n",
    "            binarized_image_mean = cv2.adaptiveThreshold(gray_image,255,cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY,11,2) #Solid but not great\n",
    "            binarized_image_gauss = cv2.adaptiveThreshold(gray_image,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2) #Better\n",
    "\n",
    "            #Both are actually good must test more and maybe adjust so the colors blue and orange get changed wht & nt blk\n",
    "\n",
    "            return gray_image\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        if not check_image_background(base_image):\n",
    "            inverted_image = cv2.bitwise_not(base_image)\n",
    "            gray_image = cv2.cvtColor(inverted_image, cv2.COLOR_BGR2GRAY)\n",
    "            binarized_image = cv2.adaptiveThreshold(gray_image,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)\n",
    "\n",
    "            return gray_image\n",
    "\n",
    "        else:\n",
    "            gray_image = cv2.cvtColor(base_image, cv2.COLOR_BGR2GRAY)\n",
    "            binarized_image_mean = cv2.adaptiveThreshold(gray_image,255,cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY,11,2) #Solid but not great\n",
    "            binarized_image_gauss = cv2.adaptiveThreshold(gray_image,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2) #Better\n",
    "            \n",
    "            return gray_image\n",
    "        \n",
    "        \n",
    "#New program works up to this point\n",
    "\n",
    "        \n",
    "#Multithread the process to speed up the image extraction        \n",
    "def process_image(file_path, df_list, alternative=False, show_image=False):\n",
    "    psm_version = \"--psm 11\"\n",
    "    \n",
    "    preprocessed_image = preprocesser(file_path, alternative)\n",
    "    \n",
    "    image_df = pd.DataFrame(pytesseract.image_to_data(preprocessed_image, output_type=Output.DICT, config=psm_version))\n",
    "    \n",
    "    time.sleep(0.1)\n",
    "\n",
    "    image_df = clean_df(image_df)\n",
    "    \n",
    "    df_list.append(image_df) #Add to a list because idk how to return when multithreading\n",
    "    \n",
    "    time.sleep(3)\n",
    "    \n",
    "    if show_image is True:\n",
    "        image_df = image_df[:-3]\n",
    "        \n",
    "        n_boxes = len(image_df['level'])\n",
    "        for i in range(n_boxes):\n",
    "            (x, y, w, h) = (int(image_df['left'][i]), int(image_df['top'][i]), int(image_df['width'][i]), int(image_df['height'][i]))\n",
    "            cv2.rectangle(preprocessed_image, (x, y), (x + w, y + h), (0,0,0), 2)\n",
    "\n",
    "        cv2.imshow('img', preprocessed_image)\n",
    "        cv2.waitKey(0)\n",
    "        \n",
    "    return\n",
    "\n",
    "    \n",
    "#Pretty sure it works up to here\n",
    "\n",
    "\n",
    "def multithread_image_processing(folder_path, dfs):\n",
    "    image_paths = get_images_paths(folder_path)\n",
    "    \n",
    "    for path in image_paths:\n",
    "        monitor_path = folder_path + \"\\\\\" + path \n",
    "        \n",
    "        threading.Thread(target=process_image, args=(monitor_path, dfs, False,)).start()\n",
    "        threading.Thread(target=process_image, args=(monitor_path, dfs, True,)).start()\n",
    "        \n",
    "    return\n",
    "\n",
    "#start refactoring here\n",
    "\n",
    "\n",
    "#Now extract lines or words from the dataframes\n",
    "def extract_text_lines(image_df):\n",
    "    df = image_df.iloc[:-3]\n",
    "    df = df[df.conf != -1]\n",
    "\n",
    "    df[\"conf\"] = pd.to_numeric(df[\"conf\"], downcast=\"float\")\n",
    "\n",
    "    #Apply only works for single columns\n",
    "    for column in [\"left\", \"top\", \"height\", \"width\"]:\n",
    "        df[column] = pd.to_numeric(df[column], downcast=\"float\")\n",
    "    \n",
    "    \n",
    "    lines = df.groupby(['page_num', 'block_num', 'par_num', 'line_num'])['text'].apply(lambda x: ' '.join(list(x))).tolist()\n",
    "    #Ifuckging hate pandas so much its never wants to let you do things easily\n",
    "    \n",
    "    left_coors = df.groupby(['page_num', 'block_num', 'par_num', 'line_num'])['left'].mean().round().tolist()\n",
    "    top_coors = df.groupby(['page_num', 'block_num', 'par_num', 'line_num'])['top'].mean().round().tolist()\n",
    "    height_coors = df.groupby(['page_num', 'block_num', 'par_num', 'line_num'])['height'].mean().round().tolist()\n",
    "    width_coors = df.groupby(['page_num', 'block_num', 'par_num', 'line_num'])['width'].mean().round().tolist()\n",
    "    \n",
    "    confs = df.groupby(['page_num', 'block_num', 'par_num', 'line_num'])['conf'].mean().tolist()\n",
    "\n",
    "    \n",
    "    return list(zip(lines, left_coors, top_coors, height_coors, width_coors))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def phrase_matching(list_of_phrases, target_phrase):\n",
    "    most_similar_phrase = \"\"\n",
    "    highest_fuzz = 0\n",
    "    similar_row = ()\n",
    "    \n",
    "    for row in list_of_phrases:\n",
    "        current_ratio = fuzz.ratio(row[0].lower(),target_phrase.lower())\n",
    "        \n",
    "        if current_ratio > highest_fuzz:\n",
    "            most_similar_phrase = row[0]\n",
    "            highest_fuzz = current_ratio\n",
    "            similar_row = row\n",
    "            \n",
    "    #print(most_similar_phrase, highest_fuzz)\n",
    "    return similar_row, highest_fuzz\n",
    "\n",
    "\n",
    "def best_match(phrases):\n",
    "    max_fuzz = 0\n",
    "    coors = 0\n",
    "    \n",
    "    for match in phrases:\n",
    "        if match[-1] > max_fuzz:\n",
    "            max_fuzz = match[-1]\n",
    "            coors = match[0][1:]\n",
    "            \n",
    "    return coors, match[-1]\n",
    "\n",
    "\n",
    "def process_phrase_coordinates(coors):\n",
    "    \"\"\"Returns coors into a clickable item for pyautogui\"\"\"\n",
    "    x = int(coors[0]) + (int(coors[-1]) // 1.5)\n",
    "    y = int(coors[1]) + (int(coors[-2]) // 1.5)\n",
    "    \n",
    "    return x,y\n",
    "\n",
    "\n",
    "def process_text_coordinates(text_row):\n",
    "    x = text_row['left'] + (text_row['width'] // 1.5)\n",
    "    y = text_row['top'] + (text_row['height'] // 1.5)\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "\n",
    "def get_images_paths(folder_path):\n",
    "    image_paths = []\n",
    "    for file in os.listdir(folder_path):\n",
    "        if \".png\" in file:\n",
    "            image_paths.append(file)\n",
    "        \n",
    "    return image_paths\n",
    "\n",
    "\n",
    "#Now take image data and find worddef locate_text(df, text):\n",
    "def locate_text(df, text):\n",
    "    results = []\n",
    "\n",
    "    stripped_text = \"\".join(text.lower().split())\n",
    "    split_text = text.split()\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        word = row['text'].lower()\n",
    "\n",
    "        second_word = df.iloc[i+1]['text'].lower()\n",
    "\n",
    "        initial_fuzz = fuzz.ratio(word, stripped_text)\n",
    "        second_fuzz = fuzz.ratio((word+second_word), stripped_text)\n",
    "        \n",
    "        if word == \"endofdataframe\":\n",
    "            break\n",
    "            \n",
    "        if initial_fuzz >= 80:\n",
    "            if initial_fuzz < second_fuzz:\n",
    "                results.append([(word+second_word), process_text_coordinates(row),second_fuzz])\n",
    "                \n",
    "            else:\n",
    "                results.append([word, process_text_coordinates(row), initial_fuzz])\n",
    "\n",
    "\n",
    "        if second_fuzz >= 80 and initial_fuzz < 80:\n",
    "            results.append([(word+second_word), process_text_coordinates(row),second_fuzz])\n",
    "                \n",
    "                \n",
    "        else:\n",
    "            if word in split_text[0] or split_text[0] in word: #may need to do partial_ratio(split_text[0], word)\n",
    "                word = word\n",
    "                second_word = word + df.iloc[i+1]['text'].lower()\n",
    "                \n",
    "                r1 = fuzz.ratio(word, stripped_text)\n",
    "                r2 = fuzz.ratio(second_word, stripped_text)\n",
    "                \n",
    "                j = i + 2 #sets j to current word in df\n",
    "                count = 0\n",
    "                \n",
    "                while r2 >= r1:\n",
    "                    word = second_word\n",
    "                    second_word = word + df.iloc[j]['text'].lower()\n",
    "                    \n",
    "                    r1 = fuzz.ratio(word, stripped_text)\n",
    "                    r2 = fuzz.ratio(second_word, stripped_text)\n",
    "                    \n",
    "                    if r2 >= 80:\n",
    "                        results.append([second_word, process_text_coordinates(row), r2])\n",
    "                    \n",
    "                    word = second_word\n",
    "                    #print(word)\n",
    "                \n",
    "                    count += 1\n",
    "                    j+=1\n",
    "                \n",
    "    return results\n",
    "\n",
    "\n",
    "def find_best_location(results):\n",
    "    highest_fuzz = 0\n",
    "    for location in results:\n",
    "        highest_fuzz = max(highest_fuzz, location[2])\n",
    "\n",
    "    for location in results:\n",
    "        if location[2] == highest_fuzz:\n",
    "            return location\n",
    "\n",
    "\n",
    "def phrase_coordinates(target, folder_path):\n",
    "    current_dir = os.getcwd()\n",
    "    path_to_tesseract = r\"C:\\Users\\sbuca\\Documents\\pierre\\autokm\\Tesseract-OCR\\tesseract.exe\" #will fail in jupyter folder\n",
    "\n",
    "    pytesseract.tesseract_cmd = path_to_tesseract\n",
    "    \n",
    "    target = target.lower()\n",
    "    best_phrases = []\n",
    "    best_text = []\n",
    "    dfs = []\n",
    "\n",
    "    multithread_image_processing(folder_path, dfs)\n",
    "    \n",
    "    while len(dfs) < (len(get_images_paths(folder_path))*2):\n",
    "        time.sleep(0.05)\n",
    "    \n",
    "    for df in dfs:\n",
    "        phrases = extract_text_lines(df)\n",
    "        best_phrase = phrase_matching(phrases, target)\n",
    "        best_phrases.append(best_phrase)\n",
    "        \n",
    "        text_results = locate_text(df, target)\n",
    "        best_text_result = find_best_location(text_results)\n",
    "        \n",
    "        if best_text_result:\n",
    "            best_text.append(best_text_result)\n",
    "           \n",
    "    final_match, fuzz = best_match(best_phrases)\n",
    "    text_final_match = find_best_location(best_text)\n",
    "    \n",
    "    print(\"BP: \", fuzz)\n",
    "    print(\"\\n\")\n",
    "    print(\"BT: \", text_final_match)\n",
    "    \n",
    "    if fuzz > text_final_match[-1]:\n",
    "        return process_phrase_coordinates(final_match)\n",
    "    \n",
    "    else:\n",
    "        return text_final_match[1]\n",
    "\n",
    "\n",
    "#Maybe toss in text coordinates just as another check\n",
    "\n",
    "        \n",
    "#Will need to refactor quitte abit -> conver the zip list into a dictionary or something \n",
    "# if __name__ == \"__main__\":\n",
    "#     phrase_coordinates(target, folder_path)\n",
    "#     process_image(file_path, df_list, alternative=False, show_image=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "316f3593",
   "metadata": {},
   "outputs": [],
   "source": [
    "xxppl = []\n",
    "\n",
    "f_path = r\"C:\\Users\\sbuca\\Documents\\pierre\\music_files\\autogui_screenshots\"\n",
    "\n",
    "multithread_image_processing(f_path, xxppl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0fb9aa6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('e', 52.0, 97.0, 6.0, 7.0),\n",
       " ('me', 48.0, 104.0, 6.0, 13.0),\n",
       " ('s', 88.0, 137.0, 9.0, 12.0),\n",
       " ('ae', 55.0, 169.0, 3.0, 16.0),\n",
       " ('ss', 157.0, 170.0, 4.0, 12.0),\n",
       " ('a', 117.0, 183.0, 5.0, 16.0),\n",
       " ('o', 1163.0, 176.0, 10.0, 10.0),\n",
       " ('a', 87.0, 187.0, 9.0, 12.0),\n",
       " ('pierre', 316.0, 189.0, 9.0, 31.0),\n",
       " ('y', 51.0, 226.0, 7.0, 6.0),\n",
       " ('ow', 293.0, 225.0, 15.0, 32.0),\n",
       " ('iy', 636.0, 229.0, 8.0, 8.0),\n",
       " ('n', 684.0, 227.0, 12.0, 10.0),\n",
       " ('view', 794.0, 231.0, 7.0, 24.0),\n",
       " ('es', 133.0, 297.0, 3.0, 13.0),\n",
       " ('uments', 478.0, 284.0, 8.0, 37.0),\n",
       " ('iene', 550.0, 286.0, 6.0, 19.0),\n",
       " ('arch pierre', 1058.0, 284.0, 9.0, 24.0),\n",
       " ('ou', 306.0, 327.0, 9.0, 29.0),\n",
       " ('me', 348.0, 330.0, 6.0, 12.0),\n",
       " ('nan', 463.0, 324.0, 9.0, 17.0),\n",
       " ('d', 711.0, 324.0, 9.0, 6.0),\n",
       " ('ified', 756.0, 324.0, 9.0, 28.0),\n",
       " ('y onedri', 306.0, 360.0, 7.0, 21.0),\n",
       " ('p', 388.0, 359.0, 9.0, 5.0),\n",
       " ('ipynbcheckpoints', 474.0, 356.0, 12.0, 97.0),\n",
       " ('2', 745.0, 364.0, 1.0, 4.0),\n",
       " ('1032 pm', 790.0, 351.0, 18.0, 18.0),\n",
       " ('file folder', 865.0, 356.0, 9.0, 22.0),\n",
       " ('com five', 1320.0, 362.0, 8.0, 20.0),\n",
       " ('au', 471.0, 390.0, 6.0, 11.0),\n",
       " ('1215 pm', 775.0, 387.0, 9.0, 17.0),\n",
       " ('fi', 855.0, 387.0, 9.0, 7.0),\n",
       " ('cuments', 348.0, 392.0, 8.0, 47.0),\n",
       " ('email attach', 352.0, 423.0, 9.0, 34.0),\n",
       " ('mand', 495.0, 418.0, 9.0, 29.0),\n",
       " ('lr', 519.0, 422.0, 7.0, 11.0),\n",
       " ('ter', 542.0, 419.0, 8.0, 20.0),\n",
       " ('v6', 713.0, 418.0, 9.0, 13.0),\n",
       " ('2', 733.0, 426.0, 1.0, 4.0),\n",
       " ('113', 762.0, 418.0, 9.0, 16.0),\n",
       " ('am', 790.0, 418.0, 9.0, 17.0),\n",
       " ('fi', 855.0, 418.0, 9.0, 7.0),\n",
       " ('os', 132.0, 445.0, 4.0, 13.0),\n",
       " ('a', 115.0, 464.0, 3.0, 11.0),\n",
       " ('music', 336.0, 455.0, 9.0, 30.0),\n",
       " ('musicfiles', 471.0, 449.0, 11.0, 56.0),\n",
       " ('v6', 713.0, 449.0, 9.0, 13.0),\n",
       " ('2', 733.0, 457.0, 1.0, 4.0),\n",
       " ('353pm', 760.0, 449.0, 9.0, 40.0),\n",
       " ('file folder', 865.0, 449.0, 9.0, 22.0),\n",
       " ('mainpyipyn', 471.0, 480.0, 12.0, 74.0),\n",
       " ('v6', 713.0, 480.0, 9.0, 13.0),\n",
       " ('2', 733.0, 488.0, 1.0, 4.0),\n",
       " ('112', 762.0, 480.0, 9.0, 17.0),\n",
       " ('am', 790.0, 480.0, 9.0, 17.0),\n",
       " ('jup', 856.0, 480.0, 12.0, 12.0),\n",
       " ('urce fil', 924.0, 482.0, 8.0, 10.0),\n",
       " ('kb', 1027.0, 480.0, 9.0, 11.0),\n",
       " ('pictures', 336.0, 487.0, 9.0, 40.0),\n",
       " ('public', 336.0, 519.0, 9.0, 31.0),\n",
       " ('ython', 347.0, 551.0, 9.0, 25.0),\n",
       " ('mo', 306.0, 615.0, 11.0, 28.0),\n",
       " ('j ds', 320.0, 642.0, 20.0, 8.0),\n",
       " ('vn', 348.0, 647.0, 9.0, 12.0),\n",
       " ('ds', 375.0, 647.0, 9.0, 10.0),\n",
       " ('documents', 328.0, 679.0, 9.0, 59.0),\n",
       " ('wr pictures', 318.0, 710.0, 11.0, 27.0),\n",
       " ('bd music', 320.0, 744.0, 10.0, 20.0),\n",
       " ('i videc', 318.0, 775.0, 13.0, 17.0),\n",
       " ('au', 328.0, 810.0, 6.0, 7.0),\n",
       " ('m', 362.0, 810.0, 6.0, 5.0),\n",
       " ('navbarbuttc', 328.0, 839.0, 11.0, 67.0),\n",
       " ('signupicons', 328.0, 874.0, 9.0, 67.0),\n",
       " ('ns', 385.0, 906.0, 6.0, 10.0),\n",
       " ('spotifyi', 328.0, 904.0, 11.0, 42.0),\n",
       " ('wi this pc', 328.0, 966.0, 10.0, 16.0),\n",
       " ('items', 298.0, 990.0, 8.0, 25.0),\n",
       " ('item s', 364.0, 990.0, 8.0, 17.0),\n",
       " ('ted', 407.0, 989.0, 9.0, 16.0),\n",
       " ('be', 1190.0, 983.0, 21.0, 38.0),\n",
       " ('73f', 51.0, 1044.0, 8.0, 23.0),\n",
       " ('a', 1225.0, 1051.0, 4.0, 16.0),\n",
       " ('rs', 1273.0, 1044.0, 10.0, 10.0),\n",
       " ('1259 pm', 1864.0, 1044.0, 8.0, 22.0),\n",
       " ('q search', 524.0, 1046.0, 20.0, 22.0),\n",
       " ('b ce rmeoe', 683.0, 1041.0, 26.0, 93.0),\n",
       " ('v', 1266.0, 1051.0, 17.0, 24.0),\n",
       " ('6', 1311.0, 1045.0, 21.0, 65.0),\n",
       " ('mostly sunny', 70.0, 1060.0, 10.0, 34.0),\n",
       " ('182023', 1849.0, 1060.0, 10.0, 48.0)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_text_lines(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5451a378",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = xxppl[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "804c3db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sbuca\\Documents\\pierre\\music_files\\autogui_screenshots\\monitor1.png\n",
      "C:\\Users\\sbuca\\Documents\\pierre\\music_files\\autogui_screenshots\\monitor2.png\n",
      "BP:  45\n",
      "\n",
      "\n",
      "BT:  None\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-ef659e56f178>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mf_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mr\"C:\\Users\\sbuca\\Documents\\pierre\\music_files\\autogui_screenshots\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mphrase_coordinates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Last Checkpoint\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-03dd269eb641>\u001b[0m in \u001b[0;36mphrase_coordinates\u001b[1;34m(target, folder_path)\u001b[0m\n\u001b[0;32m    358\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"BT: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext_final_match\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 360\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mfuzz\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mtext_final_match\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    361\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mprocess_phrase_coordinates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal_match\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "f_path = r\"C:\\Users\\sbuca\\Documents\\pierre\\music_files\\autogui_screenshots\"\n",
    "\n",
    "phrase_coordinates(\"Last Checkpoint\", f_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13e2bdcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"1\".isdigit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04e873d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from pytesseract import pytesseract\n",
    "import pyautogui\n",
    "import os\n",
    "import webbrowser\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pytesseract import Output\n",
    "import imutils\n",
    "import string \n",
    "from thefuzz import fuzz\n",
    "from Levenshtein import distance, ratio\n",
    "from numba import njit\n",
    "import mss\n",
    "from multiprocessing import Process\n",
    "import threading\n",
    "from datetime import datetime\n",
    "import time\n",
    "from thefuzz import fuzz\n",
    "from screeninfo import get_monitors\n",
    "\n",
    "\n",
    "def clean_word(word):\n",
    "    for char in word:\n",
    "        if char in string.punctuation:\n",
    "            word = word.replace(char, \"\")\n",
    "            \n",
    "    for char in word:\n",
    "        if not char.isalnum():\n",
    "            word = word.replace(char, \"\")\n",
    "            \n",
    "    return word.strip().lower()\n",
    "\n",
    "\n",
    "def clean_df(df):\n",
    "    df['text'] = df['text'].apply(lambda x: clean_word(x))\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        if row['text'] == \"\":\n",
    "            df.at[i, 'text'] = np.nan\n",
    "            \n",
    "    df.dropna(inplace=True)\n",
    "    df.reset_index(inplace=True)\n",
    "    \n",
    "    #pad dataframe for later use\n",
    "    for _ in range(3):\n",
    "        df = df.append(pd.Series(\"endofdataframe\", index=df.columns), ignore_index=True)\n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "@njit\n",
    "def check_image_background(img):\n",
    "    \"\"\"Checks if a screenshots background is mainly white\n",
    "        Will not invert if it is mainly white, changing a\n",
    "        white photo to black will reduce performance because in\n",
    "        docs it says algo performs best on white backgrounds\"\"\"\n",
    "    score = 0\n",
    "    PIXEL_MIN = 240\n",
    "    SCORE_THRESHOLD = 0.7\n",
    "\n",
    "\n",
    "    height, width, _ = img.shape\n",
    "    \n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            if img[i, j][0] >= PIXEL_MIN and img[i, j][1] >=  PIXEL_MIN and img[i, j][2] >= PIXEL_MIN:\n",
    "                score = score + 1\n",
    "                \n",
    "    if (score / (height*width)) < SCORE_THRESHOLD:\n",
    "        return 1\n",
    "    \n",
    "    return 0\n",
    "\n",
    "\n",
    "def preprocesser(file_path, opposite=False):\n",
    "    \"\"\"Allows for different preprocessing techniques to be added\n",
    "    onto our input image to improve tesseract\"\"\"\n",
    "    \n",
    "    \n",
    "    base_image = cv2.imread(file_path)\n",
    "    \n",
    "    #Current process inverts mainly black screenshots and coverts to grayscale\n",
    "    #Same process for white but no inverting (try binarization for white)\n",
    "    \n",
    "    #Cant think of a better solution for the control flow of the opposite -> will think of one late\n",
    "    if opposite is False:\n",
    "        #For photos with mainly Black background\n",
    "        if check_image_background(base_image):\n",
    "            inverted_image = cv2.bitwise_not(base_image)\n",
    "            gray_image = cv2.cvtColor(inverted_image, cv2.COLOR_BGR2GRAY)\n",
    "            binarized_image = cv2.adaptiveThreshold(gray_image,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)\n",
    "\n",
    "            return gray_image\n",
    "\n",
    "\n",
    "        #For photos with mainly White background\n",
    "        else:\n",
    "            gray_image = cv2.cvtColor(base_image, cv2.COLOR_BGR2GRAY)\n",
    "            binarized_image_mean = cv2.adaptiveThreshold(gray_image,255,cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY,11,2) #Solid but not great\n",
    "            binarized_image_gauss = cv2.adaptiveThreshold(gray_image,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2) #Better\n",
    "\n",
    "            #Both are actually good must test more and maybe adjust so the colors blue and orange get changed wht & nt blk\n",
    "\n",
    "            return gray_image\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        if not check_image_background(base_image):\n",
    "            inverted_image = cv2.bitwise_not(base_image)\n",
    "            gray_image = cv2.cvtColor(inverted_image, cv2.COLOR_BGR2GRAY)\n",
    "            binarized_image = cv2.adaptiveThreshold(gray_image,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)\n",
    "\n",
    "            return gray_image\n",
    "\n",
    "        else:\n",
    "            gray_image = cv2.cvtColor(base_image, cv2.COLOR_BGR2GRAY)\n",
    "            binarized_image_mean = cv2.adaptiveThreshold(gray_image,255,cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY,11,2) #Solid but not great\n",
    "            binarized_image_gauss = cv2.adaptiveThreshold(gray_image,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2) #Better\n",
    "            \n",
    "            return gray_image\n",
    "        \n",
    "        \n",
    "#New program works up to this point\n",
    "\n",
    "        \n",
    "#Multithread the process to speed up the image extraction        \n",
    "def process_image(file_path, df_list, monitor_number, alternative=False, show_image=False):\n",
    "    psm_version = \"--psm 11\"\n",
    "    \n",
    "    preprocessed_image = preprocesser(file_path, alternative)\n",
    "    \n",
    "    image_df = pd.DataFrame(pytesseract.image_to_data(preprocessed_image, output_type=Output.DICT, config=psm_version))\n",
    "    \n",
    "    time.sleep(0.1)\n",
    "\n",
    "    image_df = clean_df(image_df)\n",
    "    \n",
    "    df_list.append((image_df, monitor_number)) #Add to a list because idk how to return when multithreading\n",
    "    \n",
    "    time.sleep(3)\n",
    "    \n",
    "    if show_image is True:\n",
    "        image_df = image_df[:-3]\n",
    "        \n",
    "        n_boxes = len(image_df['level'])\n",
    "        for i in range(n_boxes):\n",
    "            (x, y, w, h) = (int(image_df['left'][i]), int(image_df['top'][i]), int(image_df['width'][i]), int(image_df['height'][i]))\n",
    "            cv2.rectangle(preprocessed_image, (x, y), (x + w, y + h), (0,0,0), 2)\n",
    "\n",
    "        cv2.imshow('img', preprocessed_image)\n",
    "        cv2.waitKey(0)\n",
    "        \n",
    "    return\n",
    "\n",
    "    \n",
    "#Pretty sure it works up to here\n",
    "def get_moitor_number(montior_string):\n",
    "    for char in montior_string:\n",
    "        if char.isdigit():\n",
    "            return char\n",
    "\n",
    "\n",
    "\n",
    "def multithread_image_processing(folder_path, dfs):\n",
    "    image_paths = get_images_paths(folder_path)\n",
    "    \n",
    "    for path in image_paths:\n",
    "        monitor_path = folder_path + \"\\\\\" + path \n",
    "        monitor_number = get_moitor_number(path)\n",
    "        \n",
    "        threading.Thread(target=process_image, args=(monitor_path, dfs, monitor_number, False,)).start()\n",
    "        threading.Thread(target=process_image, args=(monitor_path, dfs, monitor_number, True,)).start()\n",
    "        \n",
    "    return\n",
    "\n",
    "#start refactoring here\n",
    "\n",
    "\n",
    "#Now extract lines or words from the dataframes\n",
    "def extract_text_lines(image_df):\n",
    "    df = image_df.iloc[:-3]\n",
    "    df = df[df.conf != -1]\n",
    "\n",
    "    df[\"conf\"] = pd.to_numeric(df[\"conf\"], downcast=\"float\")\n",
    "\n",
    "    #Apply only works for single columns\n",
    "    for column in [\"left\", \"top\", \"height\", \"width\"]:\n",
    "        df[column] = pd.to_numeric(df[column], downcast=\"float\")\n",
    "    \n",
    "    \n",
    "    lines = df.groupby(['page_num', 'block_num', 'par_num', 'line_num'])['text'].apply(lambda x: ' '.join(list(x))).tolist()\n",
    "    #Ifuckging hate pandas so much its never wants to let you do things easily\n",
    "    \n",
    "    left_coors = df.groupby(['page_num', 'block_num', 'par_num', 'line_num'])['left'].mean().round().tolist()\n",
    "    top_coors = df.groupby(['page_num', 'block_num', 'par_num', 'line_num'])['top'].mean().round().tolist()\n",
    "    height_coors = df.groupby(['page_num', 'block_num', 'par_num', 'line_num'])['height'].mean().round().tolist()\n",
    "    width_coors = df.groupby(['page_num', 'block_num', 'par_num', 'line_num'])['width'].mean().round().tolist()\n",
    "    \n",
    "    confs = df.groupby(['page_num', 'block_num', 'par_num', 'line_num'])['conf'].mean().tolist()\n",
    "\n",
    "    \n",
    "    tuple_results = list(zip(lines, left_coors, top_coors, height_coors, width_coors))\n",
    "    \n",
    "    results = []\n",
    "    for row in tuple_results:\n",
    "        results.append([row[0], tuple(row[1:])])\n",
    "        \n",
    "    return results\n",
    "\n",
    "\n",
    "def locate_text(df, text):\n",
    "    results = []\n",
    "\n",
    "    stripped_text = \"\".join(text.lower().split())\n",
    "    split_text = text.split()\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        word = row['text'].lower()\n",
    "\n",
    "        second_word = df.iloc[i+1]['text'].lower()\n",
    "\n",
    "        initial_fuzz = fuzz.ratio(word, stripped_text)\n",
    "        second_fuzz = fuzz.ratio((word+second_word), stripped_text)\n",
    "        \n",
    "        if word == \"endofdataframe\":\n",
    "            break\n",
    "            \n",
    "        if initial_fuzz >= 80:\n",
    "            if initial_fuzz < second_fuzz:\n",
    "                results.append([(word+second_word), (row[\"left\"], row[\"top\"], row[\"height\"], row[\"width\"]),second_fuzz])\n",
    "                \n",
    "            else:\n",
    "                results.append([word, (row[\"left\"], row[\"top\"], row[\"height\"], row[\"width\"]), initial_fuzz])\n",
    "\n",
    "\n",
    "        if second_fuzz >= 80 and initial_fuzz < 80:\n",
    "            results.append([(word+second_word), (row[\"left\"], row[\"top\"], row[\"height\"], row[\"width\"]),second_fuzz])\n",
    "                \n",
    "                \n",
    "        else:\n",
    "            if word in split_text[0] or split_text[0] in word: #may need to do partial_ratio(split_text[0], word)\n",
    "                word = word\n",
    "                second_word = word + df.iloc[i+1]['text'].lower()\n",
    "                \n",
    "                r1 = fuzz.ratio(word, stripped_text)\n",
    "                r2 = fuzz.ratio(second_word, stripped_text)\n",
    "                \n",
    "                j = i + 2 #sets j to current word in df\n",
    "                count = 0\n",
    "                \n",
    "                while r2 >= r1:\n",
    "                    word = second_word\n",
    "                    second_word = word + df.iloc[j]['text'].lower()\n",
    "                    \n",
    "                    r1 = fuzz.ratio(word, stripped_text)\n",
    "                    r2 = fuzz.ratio(second_word, stripped_text)\n",
    "                    \n",
    "                    if r2 >= 80:\n",
    "                        results.append([second_word, (row[\"left\"], row[\"top\"], row[\"height\"], row[\"width\"]), r2])\n",
    "                    \n",
    "                    word = second_word\n",
    "                    #print(word)\n",
    "                \n",
    "                    count += 1\n",
    "                    j+=1\n",
    "                \n",
    "    return results\n",
    "\n",
    "\n",
    "def find_best_phrases(phrase_data, text):\n",
    "    results = []\n",
    "    \n",
    "    for i, row in enumerate(phrase_data):\n",
    "        r = fuzz.ratio(row[0], text)\n",
    "        phrase_data[i].append(r)\n",
    "        \n",
    "    for row in phrase_data:\n",
    "        if row[-1] >= 70:\n",
    "            results.append(row)\n",
    "            \n",
    "    return results\n",
    "\n",
    "\n",
    "def get_images_paths(folder_path):\n",
    "    image_paths = []\n",
    "    for file in os.listdir(folder_path):\n",
    "        if \".png\" in file:\n",
    "            image_paths.append(file)\n",
    "        \n",
    "    return image_paths\n",
    "\n",
    "\n",
    "def process_textual_data(data):\n",
    "    \"\"\"Find the best match to target and return coors\"\"\"\n",
    "    tmp_res = []\n",
    "    max_fuzz = 0\n",
    "    max_coors = 0\n",
    "    monitor_loc = 1\n",
    "    \n",
    "    for item in data:\n",
    "        monitor_num = item[-1]\n",
    "        item_max_fuzz = 0\n",
    "        item_max_coors = 0\n",
    "        \n",
    "        for match in item:\n",
    "            if isinstance(match,str):\n",
    "                print(match)\n",
    "                continue\n",
    "            \n",
    "            if match[-1] > item_max_fuzz:\n",
    "                item_max_fuzz = match[-1]\n",
    "                item_max_coors = match[-2]\n",
    "                \n",
    "        if item_max_fuzz > max_fuzz:\n",
    "            max_fuzz = item_max_fuzz\n",
    "            max_coors = item_max_coors\n",
    "            monitor_loc = monitor_num\n",
    "        \n",
    "    return process_coordinates(max_coors, monitor_loc)\n",
    "\n",
    "\n",
    "\n",
    "def process_coordinates(coors, monitor_num):\n",
    "    print(coors)\n",
    "    x = coors[0] + (coors[-1] // 1.5)\n",
    "    y = coors[1] + (coors[-2] // 1.5)\n",
    "    \n",
    "    #Check if monitor two and adjust coors\n",
    "    if monitor_num == \"2\":\n",
    "        monitor_data = get_monitors()[1]\n",
    "        \n",
    "        x += monitor_data.x + x\n",
    "        \n",
    "    return x, y\n",
    "        \n",
    "\n",
    "def get_coordinates(target, folder_path):\n",
    "    #Setup PyTesseract\n",
    "    current_dir = os.getcwd()\n",
    "    path_to_tesseract = r\"C:\\Users\\sbuca\\Documents\\pierre\\autokm\\Tesseract-OCR\\tesseract.exe\" #will fail in jupyter folder\n",
    "\n",
    "    pytesseract.tesseract_cmd = path_to_tesseract\n",
    "    \n",
    "    target = target.lower()\n",
    "\n",
    "    #Extract Raw Data From The Screen\n",
    "    dfs = []\n",
    "    multithread_image_processing(folder_path, dfs) \n",
    "    \n",
    "    \n",
    "    #Dynamic wait to let all threads finish\n",
    "    while len(dfs) < (len(get_images_paths(folder_path))*2):\n",
    "        time.sleep(0.05)\n",
    "    \n",
    "\n",
    "    #Finds all instances of our target (coors and monitor too)\n",
    "    data = []\n",
    "    for df, monitor_num in dfs:\n",
    "        phrase_data = extract_text_lines(df)\n",
    "        text_data = locate_text(df, target)\n",
    "\n",
    "        #Get coor and fuzz data for the lines method\n",
    "        best_phrases = find_best_phrases(phrase_data, target)\n",
    "\n",
    "        results = best_phrases + text_data\n",
    "\n",
    "        if results != []:\n",
    "            results.append(monitor_num)\n",
    "            data.append(results)\n",
    "            \n",
    "            \n",
    "    coors = process_textual_data(data)\n",
    "    return coors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be350fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "(24, 622, 10, 35)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2014.0, 628.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_coordinates(\"songs that hit like\", r\"C:\\Users\\sbuca\\Documents\\pierre\\music_files\\autogui_screenshots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "509192bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitor(x=0, y=0, width=1920, height=1080, width_mm=579, height_mm=336, name='\\\\\\\\.\\\\DISPLAY1', is_primary=True)\n",
      "Monitor(x=1920, y=0, width=1920, height=1080, width_mm=520, height_mm=320, name='\\\\\\\\.\\\\DISPLAY2', is_primary=False)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    phrase_coordinates(target, folder_path)\n",
    "    process_image(file_path, df_list, alternative=False, show_image=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ef3470ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_monitors()[1].y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b4cbf984",
   "metadata": {},
   "outputs": [],
   "source": [
    "xxppl = []\n",
    "text = \"songs that hit like\"\n",
    "\n",
    "f_path = r\"C:\\Users\\sbuca\\Documents\\pierre\\music_files\\autogui_screenshots\"\n",
    "\n",
    "multithread_image_processing(f_path, xxppl) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ae750f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for df, monitor_num in xxppl:\n",
    "    phrase_data = extract_text_lines(df)\n",
    "    text_data = locate_text(df, text)\n",
    "    \n",
    "    #Get coor and fuzz data for the lines method\n",
    "    best_phrases = find_best_phrases(phrase_data)\n",
    "    \n",
    "    results = best_phrases + text_data\n",
    "    \n",
    "    if results != []:\n",
    "        results.append(monitor_num)\n",
    "        data.append(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "58415f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_textual_data(data):\n",
    "    \"\"\"Find the best match to target and return coors\"\"\"\n",
    "    tmp_res = []\n",
    "    max_fuzz = 0\n",
    "    max_coors = 0\n",
    "    monitor_loc = 1\n",
    "    \n",
    "    for item in data:\n",
    "        monitor_num = item[-1]\n",
    "        item_max_fuzz = 0\n",
    "        item_max_coors = 0\n",
    "        \n",
    "        for match in item:\n",
    "            if isinstance(match,str):\n",
    "                print(match)\n",
    "                continue\n",
    "            \n",
    "            if match[-1] > item_max_fuzz:\n",
    "                item_max_fuzz = match[-1]\n",
    "                item_max_coors = match[-2]\n",
    "                \n",
    "        if item_max_fuzz > max_fuzz:\n",
    "            max_fuzz = item_max_fuzz\n",
    "            max_coors = item_max_coors\n",
    "            monitor_loc = monitor_num\n",
    "        \n",
    "    return process_coordinates(max_coors, monitor_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "726e2597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2014.0, 628.0)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_textual_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2565b1d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['songs that hit like clarity', (86.0, 620.0, 11.0, 26.0), 83],\n",
       "  ['songsthathit', (24, 622, 10, 35), 86],\n",
       "  ['songsthathitlike', (24, 622, 10, 35), 100],\n",
       "  ['songsthathitlikeclarity', (24, 622, 10, 35), 82],\n",
       "  '1'],\n",
       " [['songs that hit like clarity', (86.0, 620.0, 11.0, 26.0), 83],\n",
       "  ['songsthathit', (24, 622, 10, 35), 86],\n",
       "  ['songsthathitlike', (24, 622, 10, 35), 100],\n",
       "  ['songsthathitlikeclarity', (24, 622, 10, 35), 82],\n",
       "  '1']]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cafa20c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyautogui.moveTo(2014.0, 628.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9fb7d26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = extract_text_lines(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9cecbb86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['x', (1893.0, 9.0, 10.0, 10.0), 0],\n",
       " ['sbucarion', (1656.0, 26.0, 10.0, 66.0), 21],\n",
       " ['ed', (511.0, 11.0, 40.0, 364.0), 10],\n",
       " ['home', (64.0, 62.0, 10.0, 37.0), 17],\n",
       " ['artists', (641.0, 83.0, 10.0, 40.0), 31],\n",
       " ['playlists', (718.0, 83.0, 13.0, 50.0), 21],\n",
       " ['profiles', (805.0, 83.0, 10.0, 46.0), 30],\n",
       " ['podcasts shows', (926.0, 83.0, 10.0, 48.0), 30],\n",
       " ['audiobooks', (1039.0, 83.0, 10.0, 75.0), 21],\n",
       " ['search', (63.0, 102.0, 10.0, 45.0), 24],\n",
       " ['all aioums j songs', (502.0, 73.0, 30.0, 29.0), 27],\n",
       " ['your library', (80.0, 142.0, 12.0, 36.0), 26],\n",
       " ['5', (1287.0, 143.0, 7.0, 11.0), 0],\n",
       " ['0', (25.0, 137.0, 20.0, 20.0), 0],\n",
       " ['i', (1287.0, 151.0, 21.0, 11.0), 10],\n",
       " ['8888', (1521.0, 159.0, 34.0, 120.0), 0],\n",
       " ['3', (1788.0, 179.0, 19.0, 23.0), 0],\n",
       " ['9', (1736.0, 199.0, 11.0, 9.0), 0],\n",
       " ['ae', (1798.0, 200.0, 12.0, 22.0), 19],\n",
       " ['ap', (1813.0, 176.0, 31.0, 33.0), 10],\n",
       " ['create playlist', (88.0, 206.0, 12.0, 44.0), 29],\n",
       " ['si', (1767.0, 182.0, 31.0, 20.0), 19],\n",
       " ['888e', (1519.0, 205.0, 34.0, 121.0), 9],\n",
       " ['if', (1814.0, 216.0, 15.0, 10.0), 10],\n",
       " ['ai', (1351.0, 244.0, 3.0, 16.0), 19],\n",
       " ['mey', (1733.0, 230.0, 15.0, 41.0), 9],\n",
       " ['adi', (1796.0, 229.0, 12.0, 21.0), 18],\n",
       " ['9 liked songs', (64.0, 244.0, 15.0, 31.0), 31],\n",
       " ['888', (1521.0, 251.0, 34.0, 119.0), 0],\n",
       " ['iy', (681.0, 278.0, 23.0, 84.0), 10],\n",
       " ['shallow playlist', (50.0, 299.0, 12.0, 46.0), 34],\n",
       " ['her loss', (448.0, 324.0, 11.0, 29.0), 22],\n",
       " ['her loss', (661.0, 324.0, 11.0, 30.0), 22],\n",
       " ['heroes villains', (900.0, 324.0, 11.0, 67.0), 35],\n",
       " ['heroes villains', (1114.0, 324.0, 11.0, 67.0), 35],\n",
       " ['her loss', (1299.0, 316.0, 28.0, 30.0), 22],\n",
       " ['certified lover boy', (1564.0, 324.0, 12.0, 45.0), 26],\n",
       " ['honestly nevermind', (1753.0, 324.0, 13.0, 75.0), 32],\n",
       " ['my playlist 13', (56.0, 331.0, 12.0, 28.0), 30],\n",
       " ['2022 drake 21 savage', (494.0, 353.0, 11.0, 32.0), 26],\n",
       " ['2022 drake 21 savage', (708.0, 353.0, 11.0, 32.0), 26],\n",
       " ['2022 metro boomin', (906.0, 353.0, 10.0, 38.0), 22],\n",
       " ['2022 metro boomin', (1120.0, 353.0, 10.0, 38.0), 22],\n",
       " ['2023 elias', (1312.0, 353.0, 10.0, 32.0), 21],\n",
       " ['2021 drake', (1524.0, 353.0, 10.0, 32.0), 28],\n",
       " ['2022 drake', (1740.0, 353.0, 10.0, 34.0), 28],\n",
       " ['classic rock gym hype', (86.0, 363.0, 12.0, 33.0), 30],\n",
       " ['m', (23.0, 395.0, 7.0, 21.0), 0],\n",
       " ['morel', (1171.0, 437.0, 7.0, 50.0), 17],\n",
       " ['a', (1721.0, 440.0, 8.0, 12.0), 10],\n",
       " ['aa', (1847.0, 440.0, 12.0, 23.0), 10],\n",
       " ['pop 2', (40.0, 460.0, 12.0, 17.0), 17],\n",
       " ['pine', (468.0, 441.0, 25.0, 41.0), 17],\n",
       " ['8888', (879.0, 451.0, 34.0, 120.0), 0],\n",
       " ['angry', (24.0, 494.0, 10.0, 35.0), 17],\n",
       " ['a', (440.0, 476.0, 17.0, 29.0), 10],\n",
       " ['om', (459.0, 493.0, 8.0, 15.0), 10],\n",
       " ['n', (721.0, 489.0, 8.0, 9.0), 10],\n",
       " ['ad 2', (473.0, 499.0, 19.0, 20.0), 17],\n",
       " ['art', (520.0, 507.0, 7.0, 37.0), 18],\n",
       " ['old', (24.0, 523.0, 10.0, 21.0), 18],\n",
       " ['888e', (877.0, 497.0, 34.0, 121.0), 9],\n",
       " ['al', (1863.0, 508.0, 15.0, 8.0), 19],\n",
       " ['mw', (510.0, 532.0, 15.0, 16.0), 0],\n",
       " ['party music', (42.0, 556.0, 11.0, 34.0), 27],\n",
       " ['888', (879.0, 543.0, 34.0, 119.0), 0],\n",
       " ['hg', (1719.0, 517.0, 74.0, 60.0), 10],\n",
       " ['we up 3', (47.0, 587.0, 11.0, 14.0), 15],\n",
       " ['songs that hit like clarity', (86.0, 620.0, 11.0, 26.0), 83],\n",
       " ['savage mode ii', (494.0, 616.0, 11.0, 40.0), 36],\n",
       " ['never liked you', (706.0, 611.0, 22.0, 44.0), 35],\n",
       " ['certified lover boy', (922.0, 616.0, 12.0, 45.0), 26],\n",
       " ['sneakin', (1073.0, 615.0, 12.0, 63.0), 31],\n",
       " ['her loss', (1303.0, 616.0, 11.0, 27.0), 22],\n",
       " ['her', (1502.0, 616.0, 11.0, 44.0), 18],\n",
       " ['antisocial', (1715.0, 615.0, 12.0, 74.0), 28],\n",
       " ['2020 21 savage metro', (490.0, 645.0, 11.0, 32.0), 21],\n",
       " ['2022 future', (670.0, 645.0, 10.0, 35.0), 20],\n",
       " ['2021 drake', (882.0, 645.0, 10.0, 32.0), 28],\n",
       " ['2016 drake', (1096.0, 645.0, 10.0, 32.0), 28],\n",
       " ['2022 yngxscrap', (1312.0, 646.0, 10.0, 52.0), 24],\n",
       " ['2017 her', (1524.0, 645.0, 10.0, 32.0), 22],\n",
       " ['2021 tana slump6s', (1756.0, 645.0, 11.0, 38.0), 28],\n",
       " ['rock classics', (42.0, 651.0, 10.0, 40.0), 25],\n",
       " ['boomin', (432.0, 667.0, 10.0, 46.0), 16],\n",
       " ['karaoke', (24.0, 683.0, 10.0, 50.0), 23],\n",
       " ['kanye', (24.0, 715.0, 13.0, 37.0), 17],\n",
       " ['oo', (752.0, 744.0, 13.0, 19.0), 10],\n",
       " ['par', (887.0, 748.0, 8.0, 18.0), 9],\n",
       " ['al', (1347.0, 748.0, 7.0, 42.0), 19],\n",
       " ['pop', (24.0, 750.0, 10.0, 23.0), 9],\n",
       " ['in', (779.0, 755.0, 5.0, 13.0), 10],\n",
       " ['c2', (1158.0, 752.0, 11.0, 20.0), 0],\n",
       " ['oe closs', (1126.0, 758.0, 16.0, 53.0), 22],\n",
       " ['yak', (23.0, 779.0, 13.0, 22.0), 18],\n",
       " ['tt', (1349.0, 761.0, 27.0, 34.0), 19],\n",
       " ['ae', (733.0, 781.0, 24.0, 44.0), 19],\n",
       " ['r', (1349.0, 790.0, 14.0, 10.0), 0],\n",
       " ['carter', (24.0, 812.0, 9.0, 36.0), 24],\n",
       " ['faster', (453.0, 820.0, 9.0, 58.0), 24],\n",
       " ['her loss', (911.0, 822.0, 28.0, 53.0), 22],\n",
       " ['see', (1550.0, 824.0, 7.0, 21.0), 18],\n",
       " ['ms', (1622.0, 815.0, 21.0, 37.0), 10],\n",
       " ['m', (24.0, 843.0, 10.0, 11.0), 0],\n",
       " ['e', (454.0, 834.0, 20.0, 99.0), 10],\n",
       " ['vv', (1132.0, 801.0, 43.0, 49.0), 0],\n",
       " ['sje', (431.0, 851.0, 19.0, 43.0), 18],\n",
       " ['ee', (725.0, 852.0, 8.0, 29.0), 10],\n",
       " ['i', (789.0, 856.0, 5.0, 6.0), 10],\n",
       " ['chicago', (24.0, 875.0, 13.0, 51.0), 15],\n",
       " ['a', (560.0, 886.0, 5.0, 15.0), 10],\n",
       " ['dr ar www', (716.0, 873.0, 17.0, 24.0), 21],\n",
       " ['torloayel', (1077.0, 872.0, 20.0, 74.0), 21],\n",
       " ['z', (1820.0, 870.0, 27.0, 38.0), 0],\n",
       " ['fasterher loss', (484.0, 920.0, 11.0, 69.0), 30],\n",
       " ['her loss', (661.0, 920.0, 11.0, 30.0), 22],\n",
       " ['her loss', (875.0, 920.0, 11.0, 30.0), 22],\n",
       " ['her loss', (1089.0, 920.0, 11.0, 30.0), 22],\n",
       " ['her loss', (1303.0, 920.0, 11.0, 30.0), 22],\n",
       " ['hard place', (1522.0, 920.0, 11.0, 38.0), 34],\n",
       " ['her love still haun', (1766.0, 920.0, 11.0, 35.0), 26],\n",
       " ['wa', (864.0, 966.0, 14.0, 16.0), 10],\n",
       " ['e', (1689.0, 987.0, 1.0, 14.0), 10],\n",
       " ['2', (1689.0, 979.0, 5.0, 14.0), 0],\n",
       " ['000', (615.0, 1001.0, 8.0, 24.0), 0],\n",
       " ['000', (1282.0, 1001.0, 8.0, 23.0), 0],\n",
       " ['6af', (51.0, 1044.0, 8.0, 23.0), 9],\n",
       " ['q search', (504.0, 1050.0, 12.0, 25.0), 22],\n",
       " ['fe', (1200.0, 1046.0, 12.0, 22.0), 10],\n",
       " ['se', (1383.0, 1044.0, 14.0, 14.0), 19],\n",
       " ['a', (1710.0, 1053.0, 6.0, 10.0), 10],\n",
       " ['a', (1739.0, 1048.0, 9.0, 15.0), 10],\n",
       " ['re', (1740.0, 1056.0, 8.0, 15.0), 10],\n",
       " ['aw', (1771.0, 1050.0, 12.0, 34.0), 10],\n",
       " ['1246 m', (1844.0, 1044.0, 8.0, 22.0), 8],\n",
       " ['sunny', (51.0, 1060.0, 11.0, 33.0), 17],\n",
       " ['scrmaootes', (629.0, 1044.0, 31.0, 374.0), 28],\n",
       " ['o 76', (1270.0, 1042.0, 32.0, 42.0), 17],\n",
       " ['ss', (1378.0, 1057.0, 18.0, 18.0), 19],\n",
       " ['arpe023', (1829.0, 1060.0, 10.0, 48.0), 15]]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "03e3f5e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzz.ratio(\"songs that hit like\", \"your library\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3e9fb291",
   "metadata": {},
   "outputs": [],
   "source": [
    "ghp = locate_text(df, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "91dd13b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hmf = [5,6,7,8]\n",
    "hmf.append([1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "eaf04b04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 6, 7, 8, [1, 2, 3, 4]]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "01b3e377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1,2,3,4] + [5,6,7,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4370ca02",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlm = best_phrases(pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "29cb8c49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['songs that hit like clarity', (86.0, 620.0, 11.0, 26.0), 83]]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1894b78a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['songsthathit', (24, 622, 10, 35), 86],\n",
       " ['songsthathitlike', (24, 622, 10, 35), 100],\n",
       " ['songsthathitlikeclarity', (24, 622, 10, 35), 82]]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ghp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3dd1f6e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['songsthathit', (24, 622, 10, 35), 86],\n",
       " ['songsthathitlike', (24, 622, 10, 35), 100],\n",
       " ['songsthathitlikeclarity', (24, 622, 10, 35), 82],\n",
       " ['songs that hit like clarity', (86.0, 620.0, 11.0, 26.0), 83]]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ghp + xlm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a21ce2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
